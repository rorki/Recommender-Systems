{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conventional Matrix Factorization & Random Predictor Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all aux imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from collections import namedtuple, defaultdict\n",
    "import os\n",
    "\n",
    "# random seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# surplrise lib\n",
    "from surprise import Dataset, Reader, SVD, NormalPredictor, BaselineOnly\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# visualizaion\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "XP_NAME = 'baselines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make dirs if not exist\n",
    "if not os.path.isdir('./xps/'):\n",
    "    os.mkdir('./xps/')\n",
    "\n",
    "if not os.path.isdir('./xps/' + XP_NAME):\n",
    "    os.mkdir('./xps/' + XP_NAME)\n",
    "    \n",
    "XP_DIR = './xps/' + XP_NAME + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare XP log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define aux functions\n",
    "def write_row(file, row):\n",
    "    with open(file, \"a\", newline='') as fp:\n",
    "        wr = csv.writer(fp, dialect='excel')\n",
    "        wr.writerow(row)\n",
    "    \n",
    "## this should be used to save xp row\n",
    "def write_to_csv(xp_row):\n",
    "    predictor_file = Path('%s%s.csv' % (XP_DIR, xp_row.xpdata.label))\n",
    "    # write headers if file not yet created\n",
    "    if not predictor_file.exists():\n",
    "        write_row(str(predictor_file), ['category', 'predictor', 'nfactors', 'rmse', 'mae'])\n",
    "    \n",
    "    # write header if file not yet created\n",
    "    recall_precision_file = Path( '%skpr_%s_%s.csv' % (XP_DIR, xp_row.xpdata.label, xp_row.dataset))    \n",
    "    if not recall_precision_file.exists():\n",
    "        write_row(str(recall_precision_file), ['category', 'predictor', 'nfactors', 'k', 'recall', 'precision'])\n",
    "    \n",
    "    # write data\n",
    "    write_row(str(predictor_file), [xp_row.dataset, xp_row.xpdata.label, xp_row.xpdata.nfactors,\n",
    "               xp_row.rmse, xp_row.mae])\n",
    "    \n",
    "    for k in xp_row.recall:\n",
    "        write_row(str(recall_precision_file), [xp_row.dataset, xp_row.xpdata.label, xp_row.xpdata.nfactors, k,\n",
    "               xp_row.recall[k], xp_row.precision[k]])\n",
    "    \n",
    "   \n",
    "## define named tuples\n",
    "XPData = namedtuple('XPData', ['predictor', 'label', 'nfactors'])\n",
    "XPRow = namedtuple('XPRow', ['dataset', 'xpdata', 'rmse', 'mae', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and run predictors per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'lr_all': 0.002, 'n_epochs': 100, 'n_factors': 15, 'reg_all': 0.05}\n",
    "#predictors = [XPData(predictor = NormalPredictor(), label = 'Normal Predictor', nfactors = None)]\n",
    "predictors = [XPData(predictor = SVD(n_factors = 15, lr_all=0.002, n_epochs=120, reg_all=0.05), label = 'SVD_15', nfactors = 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_complete_ds(file):\n",
    "    chunk_num = 1 \n",
    "    \n",
    "    dfs = []\n",
    "    print('Chunks: ', end='')\n",
    "    for df_chunky in pd.read_json(str(file), lines=True, compression = 'gzip', chunksize=1000000):\n",
    "        print('#%s' % chunk_num, end=' ')\n",
    "        chunk_num += 1\n",
    "        dfs.append(df_chunky[['reviewerID', 'asin', 'overall']].copy())\n",
    "        \n",
    "    complete_df = pd.concat(dfs)\n",
    "    print(\"\\nLoading is completed, df shape %s x %s\" % complete_df.shape)\n",
    "    return complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions):\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "    mae = accuracy.mae(predictions, verbose=False)\n",
    "\n",
    "    k_prec = {}\n",
    "    k_rec = {}\n",
    "\n",
    "    #print('RMSE = %s, MAE = %s' % (rmse, mae))\n",
    "    #print('=== Precision@k and Recall@k ===')\n",
    "    #print('k\\tprecision\\trecall')\n",
    "\n",
    "    for k in range(0, 201, 5):\n",
    "        precisions, recalls = precision_recall_at_k(predictions, k=k, threshold=3) \n",
    "        p_mean = np.mean(list(precisions.values()))\n",
    "        r_mean = np.mean(list(recalls.values()))\n",
    "        k_prec[k] = p_mean\n",
    "        k_rec[k] = r_mean\n",
    "        #print('%s\\t%s\\t%s' % (k, p_mean, r_mean))\n",
    "        \n",
    "    return rmse, mae, k_prec, k_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for: Video Games\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 231780 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "RMSE = 1.5630152634465895, MAE = 1.1973105276635212\n",
      "=== Precision@k and Recall@k ===\n",
      "Loading data for: Toys and Games\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 167597 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "RMSE = 1.262698531864113, MAE = 0.9341908487260474\n",
      "=== Precision@k and Recall@k ===\n",
      "Loading data for: Sports and Outdoors\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 296337 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "RMSE = 1.257402705931803, MAE = 0.9184510249177197\n",
      "=== Precision@k and Recall@k ===\n",
      "Loading data for: Movies and TV\n",
      "Chunks: #1 #2 \n",
      "Loading is completed, df shape 1697533 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "RMSE = 1.5463269143356195, MAE = 1.1808444664785984\n",
      "=== Precision@k and Recall@k ===\n",
      "Loading data for: Kindle Store\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 982619 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "RMSE = 1.2292246021618178, MAE = 0.9152164151281936\n",
      "=== Precision@k and Recall@k ===\n",
      "Loading data for: Home and Kitchen\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 551682 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "RMSE = 1.4168053336772604, MAE = 1.040902920204206\n",
      "=== Precision@k and Recall@k ===\n",
      "Loading data for: Health and Personal Care\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 346355 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "RMSE = 1.4364675929447548, MAE = 1.069631774505002\n",
      "=== Precision@k and Recall@k ===\n",
      "Loading data for: Electronics\n",
      "Chunks: #1 #2 \n",
      "Loading is completed, df shape 1689188 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "RMSE = 1.515736194288244, MAE = 1.1310647598907921\n",
      "=== Precision@k and Recall@k ===\n",
      "Loading data for: Clothing Shoes and Jewelry\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 278677 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "RMSE = 1.4137673840105707, MAE = 1.0623327404391174\n",
      "=== Precision@k and Recall@k ===\n",
      "Loading data for: Cell Phones and Accessories\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 194439 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "RMSE = 1.5705279338587053, MAE = 1.1929894517938484\n",
      "=== Precision@k and Recall@k ===\n",
      "Loading data for: CDs and Vinyl\n",
      "Chunks: #1 #2 \n",
      "Loading is completed, df shape 1097592 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "RMSE = 1.3745747498835228, MAE = 1.0197479909299354\n",
      "=== Precision@k and Recall@k ===\n",
      "Loading data for: Books\n",
      "Chunks: #1 #2 #3 #4 #5 #6 #7 #8 #9 \n",
      "Loading is completed, df shape 8898041 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "RMSE = 1.3619359309928147, MAE = 1.0247878993028232\n",
      "=== Precision@k and Recall@k ===\n"
     ]
    }
   ],
   "source": [
    "parent_path = r'D:\\Datasets\\amazon_reviews\\gzips'\n",
    "files = [Path(f) for f in glob.glob(parent_path  + r\"\\*.gz\", recursive=False)]\n",
    "\n",
    "for file in files:\n",
    "    label = ' '.join(file.stem.split('_')[1:-1])\n",
    "    print('Loading data for: ' + label)              \n",
    "    \n",
    "    complete_df = read_complete_ds(file)\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    ds = Dataset.load_from_df(complete_df[['reviewerID', 'asin', 'overall']], reader)\n",
    "    trainset, testset = train_test_split(ds, random_state=42, test_size=0.3)\n",
    "    \n",
    "    for pred in predictors:\n",
    "        print(\"Run predictor %s\" % pred.label)\n",
    "        \n",
    "        pred.predictor.fit(trainset)\n",
    "        predictions = pred.predictor.test(testset)\n",
    "        \n",
    "        print(\"Write eval data to file\")\n",
    "        rmse, mae, k_prec, k_rec = evaluate(predictions)\n",
    "        write_to_csv(XPRow(dataset=label, xpdata=pred, rmse=rmse, mae=mae, precision=k_prec, recall=k_rec))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks: #1 \n",
      "Loading is completed, df shape 194439 x 3\n"
     ]
    }
   ],
   "source": [
    "complete_df = read_complete_ds(Path(r'D:\\Datasets\\amazon_reviews\\gzips\\reviews_Cell_Phones_and_Accessories_5.json.gz'))\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "ds = Dataset.load_from_df(complete_df[['reviewerID', 'asin', 'overall']], reader)\n",
    "trainset, testset = train_test_split(ds, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratings = ds.raw_ratings\n",
    "random.shuffle(raw_ratings)\n",
    "\n",
    "threshold = int(.7 * len(raw_ratings))\n",
    "train_raw_ratings = raw_ratings[:threshold]\n",
    "test_raw_ratings = raw_ratings[threshold:]\n",
    "\n",
    "ds.raw_ratings = train_raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=10)]: Done 324 out of 324 | elapsed: 13.8min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_epochs': [50, 100, 150], 'lr_all': [0.001, 0.002, 0.003], \n",
    "              'n_factors':[10, 12, 15, 17], 'reg_all': [0.05, 0.06, 0.07]}\n",
    "\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=10, joblib_verbose=1)\n",
    "grid_search.fit(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr_all': 0.002, 'n_epochs': 50, 'n_factors': 12, 'reg_all': 0.05}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr_all': 0.002, 'n_epochs': 150, 'n_factors': 10, 'reg_all': 0.07}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params['mae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1483129315790315, MAE: 0.8890311814329908\n"
     ]
    }
   ],
   "source": [
    "trainset = ds.build_full_trainset()\n",
    "algo = grid_search.best_estimator['rmse']\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(ds.construct_testset(test_raw_ratings))\n",
    "rmse, mae, k_prec, k_rec = evaluate(predictions)\n",
    "print('RMSE: %s, MAE: %s' % (rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.164126078187515, MAE: 0.8760092479109463\n"
     ]
    }
   ],
   "source": [
    "algo = grid_search.best_estimator['mae']\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(ds.construct_testset(test_raw_ratings))\n",
    "rmse, mae, k_prec, k_rec = evaluate(predictions)\n",
    "print('RMSE: %s, MAE: %s' % (rmse, mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cat | mae best | mae | rmse | rmse best | mae | rmse\n",
    "--- | --- | --- | --- | --- | --- | --- |\n",
    "Movies and TV | {'lr_all': 0.002, 'n_epochs': 100, 'n_factors': 15, 'reg_all': 0.05} | 0.746238556042999 | 1.0126716530928812 | {'lr_all': 0.003, 'n_epochs': 50, 'n_factors': 15, 'reg_all': 0.05} | 0.7485903901212774 | 1.0077799950679822 | \n",
    "Video_Games | {'lr_all': 0.003, 'n_epochs': 100, 'n_factors': 15, 'reg_all': 0.04} | 0.8128197857525622 | 1.0819106948711148 | {'lr_all': 0.001, 'n_epochs': 150, 'n_factors': 20, 'reg_all': 0.04} | 0.8211216841776046 | 1.074492851316181  |\n",
    "Cell Phones and Accessories | {'lr_all': 0.002, 'n_epochs': 150, 'n_factors': 15, 'reg_all': 0.05} | 0.8795520166249166 | 1.166180286615277 | {'lr_all': 0.002, 'n_epochs': 50, 'n_factors': 15, 'reg_all': 0.05} | 0.890115861820871 | 1.1476024506824996 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
