{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess review & summary texts in Amazon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import glob\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "import concurrent.futures\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_2_dataframe(path): \n",
    "    df = pd.read_json(path, compression='gzip', lines=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(nlp):\n",
    "    prefix_re = spacy.util.compile_prefix_regex(nlp.Defaults.prefixes)\n",
    "    suffix_re = spacy.util.compile_suffix_regex(nlp.Defaults.suffixes)\n",
    "    custom_infixes = ['\\.\\.\\.+', '(?<=[0-9])-(?=[0-9])', '[!&:,()]']\n",
    "    infix_re = spacy.util.compile_infix_regex(custom_infixes)\n",
    "\n",
    "    tokenizer = spacy.tokenizer.Tokenizer(nlp.vocab,\n",
    "                                        nlp.Defaults.tokenizer_exceptions,\n",
    "                                        prefix_re.search,\n",
    "                                        suffix_re.search,\n",
    "                                        infix_re.finditer,\n",
    "                                        token_match=None)\n",
    "    return lambda text: tokenizer(text)\n",
    "\n",
    "def process_data_with_spacy(review_data):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    return [text_to_seq(s, nlp) for s in review_data]\n",
    "\n",
    "def text_to_seq (s, nlp):\n",
    "    doc = nlp(s)\n",
    "    tokens = []\n",
    "    \n",
    "    for tok in doc:\n",
    "        if not tok.is_stop and not tok.is_punct and not tok.like_url and not tok.like_email:\n",
    "            tokens.append(tok.lemma_.lower().strip() if tok.lemma_ != '-PRON-' else tok.lower_)\n",
    "    return tokens\n",
    "\n",
    "def text_to_text(s, nlp):\n",
    "    return ' '.join(text_to_seq(s, nlp))\n",
    "\n",
    "def process_data_with_spacy_df(df):\n",
    "    \n",
    "    df['reviewTextProc'] = df.apply (lambda row: text_to_text(row['reviewText'], nlp), axis=1)\n",
    "    df['summaryProc'] = df.apply (lambda row: text_to_text(row['summary'], nlp), axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gzip_path = r'D:\\Datasets\\amazon_reviews\\gzips'\n",
    "ds_proc_path = r'D:\\Datasets\\amazon_reviews\\processed'\n",
    "\n",
    "files = [Path(f) for f in glob.glob(ds_gzip_path + r\"\\*.gz\", recursive=False)]\n",
    "files.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import cpu_count, Pool\n",
    " \n",
    "cores = cpu_count() - 4 #Number of CPU cores on your system\n",
    "partitions = cores #Define as many partitions as you want\n",
    " \n",
    "def parallelize(data, func):\n",
    "    data_split = np.array_split(data, partitions)\n",
    "    print('DF is splitted to {} partitions'.format(partitions))\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=cores) as executor:\n",
    "        data_proc = pd.concat(executor.map(func, data_split))\n",
    "        return data_proc\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing reviews_Books_5.json\n",
      "Chunk #0\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #1\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #2\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #3\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #4\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #5\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #6\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #7\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #8\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #9\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #10\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #11\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #12\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #13\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #14\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #15\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #16\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #17\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #18\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #19\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #20\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #21\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #22\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #23\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #24\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #25\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #26\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #27\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #28\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #29\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #30\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #31\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #32\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #33\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #34\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #35\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #36\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #37\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #38\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n",
      "Shape of processed DF: (100000, 11)\n",
      "Chunk #39\n",
      "Shape of DF: (100000, 9)\n",
      "DF is splitted to 8 partitions\n"
     ]
    }
   ],
   "source": [
    "files = [Path(ds_gzip_path + '\\\\reviews_Books_5.json.gz')]\n",
    "\n",
    "for f in files:\n",
    "    print(\"Start processing \" + f.stem)\n",
    "    \n",
    "    chunk_num = 0\n",
    "    for df_chunky in pd.read_json(str(f), lines=True, compression = 'gzip', chunksize=100000):\n",
    "        print('Chunk #%s' % chunk_num)\n",
    "        chunk_num += 1\n",
    "        \n",
    "        print(\"Shape of DF: \" + str(df_chunky.shape))\n",
    "        df_proc = parallelize(df_chunky, process_data_with_spacy_df);\n",
    "        #df_proc = process_data_with_spacy_df(df_chunky)\n",
    "\n",
    "        print(\"Shape of processed DF: \" + str(df_proc.shape))\n",
    "        with open(ds_proc_path + \"/\" + f.stem, mode='a') as out_file:\n",
    "            df_proc.to_csv(out_file, header=out_file.tell()==0,  mode='a')\n",
    "\n",
    "    print(\"Processing of \" + f.stem + \" is finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('D:/Datasets/amazon_reviews/gzips/reviews_Video_Games_5.json.gz'),\n",
       " WindowsPath('D:/Datasets/amazon_reviews/gzips/reviews_Toys_and_Games_5.json.gz'),\n",
       " WindowsPath('D:/Datasets/amazon_reviews/gzips/reviews_Sports_and_Outdoors_5.json.gz'),\n",
       " WindowsPath('D:/Datasets/amazon_reviews/gzips/reviews_Movies_and_TV_5.json.gz'),\n",
       " WindowsPath('D:/Datasets/amazon_reviews/gzips/reviews_Kindle_Store_5.json.gz'),\n",
       " WindowsPath('D:/Datasets/amazon_reviews/gzips/reviews_Home_and_Kitchen_5.json.gz'),\n",
       " WindowsPath('D:/Datasets/amazon_reviews/gzips/reviews_Health_and_Personal_Care_5.json.gz'),\n",
       " WindowsPath('D:/Datasets/amazon_reviews/gzips/reviews_Electronics_5.json.gz'),\n",
       " WindowsPath('D:/Datasets/amazon_reviews/gzips/reviews_Clothing_Shoes_and_Jewelry_5.json.gz'),\n",
       " WindowsPath('D:/Datasets/amazon_reviews/gzips/reviews_Cell_Phones_and_Accessories_5.json.gz'),\n",
       " WindowsPath('D:/Datasets/amazon_reviews/gzips/reviews_CDs_and_Vinyl_5.json.gz'),\n",
       " WindowsPath('D:/Datasets/amazon_reviews/gzips/reviews_Books_5.json.gz'),\n",
       " WindowsPath('D:/Datasets/amazon_reviews/gzips/meta_Video_Games.json.gz'),\n",
       " WindowsPath('D:/Datasets/amazon_reviews/gzips/meta_Toys_and_Games.json.gz')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield l\n",
    "\n",
    "def get_dataframe(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        dec = json.loads(d.decode('utf8'))\n",
    "        df[i] = dec\n",
    "        i += 1\n",
    "        if i % 10000 == 0:\n",
    "            break\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dataframe(str(files[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Best Price</td>\n",
       "      <td>10 19, 2013</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>My daughter wanted this book and the price on ...</td>\n",
       "      <td>1382140800</td>\n",
       "      <td>APYOBQE6M18AA</td>\n",
       "      <td>0615391206</td>\n",
       "      <td>Martin Schwartz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>zoku</td>\n",
       "      <td>06 18, 2014</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I bought this zoku quick pop for my daughterr ...</td>\n",
       "      <td>1403049600</td>\n",
       "      <td>A1JVQTAGHYOL7F</td>\n",
       "      <td>0615391206</td>\n",
       "      <td>Michelle Dinh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Excels at Sweet Dessert Pops, but Falls Short ...</td>\n",
       "      <td>05 5, 2013</td>\n",
       "      <td>[26, 27]</td>\n",
       "      <td>There is no shortage of pop recipes available ...</td>\n",
       "      <td>1367712000</td>\n",
       "      <td>A3UPYGJKZ0XTU4</td>\n",
       "      <td>0615391206</td>\n",
       "      <td>mirasreviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Creative Combos</td>\n",
       "      <td>08 4, 2011</td>\n",
       "      <td>[14, 18]</td>\n",
       "      <td>This book is a must have if you get a Zoku (wh...</td>\n",
       "      <td>1312416000</td>\n",
       "      <td>A2MHCTX43MIMDZ</td>\n",
       "      <td>0615391206</td>\n",
       "      <td>M. Johnson \"Tea Lover\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>A must own if you own the Zoku maker...</td>\n",
       "      <td>06 7, 2014</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This cookbook is great.  I have really enjoyed...</td>\n",
       "      <td>1402099200</td>\n",
       "      <td>AHAI85T5C2DH3</td>\n",
       "      <td>0615391206</td>\n",
       "      <td>PugLover</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                            summary   reviewTime  \\\n",
       "0      5.0                                         Best Price  10 19, 2013   \n",
       "1      5.0                                               zoku  06 18, 2014   \n",
       "2      4.0  Excels at Sweet Dessert Pops, but Falls Short ...   05 5, 2013   \n",
       "3      5.0                                    Creative Combos   08 4, 2011   \n",
       "4      4.0            A must own if you own the Zoku maker...   06 7, 2014   \n",
       "\n",
       "    helpful                                         reviewText  \\\n",
       "0    [0, 0]  My daughter wanted this book and the price on ...   \n",
       "1    [0, 0]  I bought this zoku quick pop for my daughterr ...   \n",
       "2  [26, 27]  There is no shortage of pop recipes available ...   \n",
       "3  [14, 18]  This book is a must have if you get a Zoku (wh...   \n",
       "4    [0, 0]  This cookbook is great.  I have really enjoyed...   \n",
       "\n",
       "   unixReviewTime      reviewerID        asin            reviewerName  \n",
       "0      1382140800   APYOBQE6M18AA  0615391206         Martin Schwartz  \n",
       "1      1403049600  A1JVQTAGHYOL7F  0615391206           Michelle Dinh  \n",
       "2      1367712000  A3UPYGJKZ0XTU4  0615391206            mirasreviews  \n",
       "3      1312416000  A2MHCTX43MIMDZ  0615391206  M. Johnson \"Tea Lover\"  \n",
       "4      1402099200   AHAI85T5C2DH3  0615391206                PugLover  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good - large - some foods &#34;stick&#34; inside diswasher This is a good set - as others have noted each utensil is large - but I like that - they are heavy duty and strudy -  however, I have noticed some foods tend to stick to the unesils, even when run thru a dishwasher cycle'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_num = 5811\n",
    "s = df.iloc[review_num].summary + ' '+ df.iloc[review_num].reviewText\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df.iloc[39190].summary +' '+ df.iloc[39190].reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I Love this Game! This game is one of the best games for Game Cube. You play as a kid named Billy who goes on an exciting adventure to save a happy world from evil crows who are led by The Dark Raven who is led by The KING CROW. And if that doesn't sound fun enough this game also comes with a really fun two player battle mode where you hatch cute animals from eggs! This fun game is for all ages!\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(s)\n",
    "tokens = []\n",
    "\n",
    "for tok in doc:\n",
    "    if not tok.is_stop and not tok.is_punct and not tok.like_url and not tok.like_email:\n",
    "        tokens.append(tok.lemma_.lower().strip() if tok.lemma_ != '-PRON-' else tok.lower_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great i like thing it play color battery fast the sound not great quiet screen scratch easily'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
