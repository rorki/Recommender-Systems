{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from scipy.sparse import csr_matrix\n",
    "#init random seed\n",
    "np.random.seed(5)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/home/neopux/UHH/datasets/Video_Games_5_proc.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTextProc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>[8, 12]</td>\n",
       "      <td>1</td>\n",
       "      <td>Installing the game was a struggle (because of...</td>\n",
       "      <td>07 9, 2012</td>\n",
       "      <td>A2HD75EMZR8QLN</td>\n",
       "      <td>123</td>\n",
       "      <td>Pay to unlock content? I don't think so.</td>\n",
       "      <td>1341792000</td>\n",
       "      <td>instal game struggle game window live bugs).so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>4</td>\n",
       "      <td>If you like rally cars get this game you will ...</td>\n",
       "      <td>06 30, 2013</td>\n",
       "      <td>A3UR8NLLY1ZHCX</td>\n",
       "      <td>Alejandro Henao \"Electronic Junky\"</td>\n",
       "      <td>Good rally game</td>\n",
       "      <td>1372550400</td>\n",
       "      <td>if like rally car game fun it orient 34;europe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  helpful  overall  \\\n",
       "0  0700099867  [8, 12]        1   \n",
       "1  0700099867   [0, 0]        4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Installing the game was a struggle (because of...   07 9, 2012   \n",
       "1  If you like rally cars get this game you will ...  06 30, 2013   \n",
       "\n",
       "       reviewerID                        reviewerName  \\\n",
       "0  A2HD75EMZR8QLN                                 123   \n",
       "1  A3UR8NLLY1ZHCX  Alejandro Henao \"Electronic Junky\"   \n",
       "\n",
       "                                    summary  unixReviewTime  \\\n",
       "0  Pay to unlock content? I don't think so.      1341792000   \n",
       "1                           Good rally game      1372550400   \n",
       "\n",
       "                                      reviewTextProc  \n",
       "0  instal game struggle game window live bugs).so...  \n",
       "1  if like rally car game fun it orient 34;europe...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df_train.groupby('asin').reviewTextProc.agg(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "vectorizer.fit(reviews.values)\n",
    "\n",
    "item_infomation_matrix = vectorizer.transform(reviews.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10666, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(item_infomation_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('instal', 4626),\n",
       " ('game', 3718),\n",
       " ('struggle', 8522),\n",
       " ('window', 9806),\n",
       " ('live', 5190),\n",
       " ('bugs', 1333),\n",
       " ('some', 8180),\n",
       " ('championship', 1545),\n",
       " ('race', 7004),\n",
       " ('car', 1444),\n",
       " ('unlocked', 9345),\n",
       " ('buy', 1377),\n",
       " ('addon', 342),\n",
       " ('pay', 6419),\n",
       " ('nearly', 5887),\n",
       " ('30', 129),\n",
       " ('dollar', 2691),\n",
       " ('new', 5933),\n",
       " ('not', 6010),\n",
       " ('like', 5145)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectorizer.vocabulary_.items())[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scense',\n",
       " 'collider',\n",
       " 'unleashedrace',\n",
       " 'clangy',\n",
       " 'skyalnder',\n",
       " '48mbpulse',\n",
       " 'pandoran',\n",
       " 'statewide',\n",
       " 'sleet',\n",
       " 'preplay']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectorizer.stop_words_)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_infomation_matrix = np.array(item_infomation_matrix.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build rating matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin = CategoricalDtype(sorted(df_train.asin.unique()), ordered=True)\n",
    "rev_id = CategoricalDtype(sorted(df_train.reviewerID.unique()), ordered=True)\n",
    "\n",
    "row_cat = df_train.reviewerID.astype(rev_id).cat\n",
    "col_cat = df_train.asin.astype(asin).cat\n",
    "\n",
    "row = row_cat.codes\n",
    "col = col_cat.codes\n",
    "\n",
    "sparse_matrix = csr_matrix((df_train[\"overall\"].values, (row, col)), \\\n",
    "                           shape=(rev_id.categories.size, asin.categories.size), dtype = 'd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix = sparse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save matrix by pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:/Datasets/amazon_reviews/cdl_item_infomation_matrix.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(r'D:/Datasets/amazon_reviews/cdl_rating_matrix.pickle', 'wb') as handle:\n",
    "    pickle.dump(rating_matrix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load matrix from pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:/Datasets/amazon_reviews/cdl_item_infomation_matrix.pickle', 'rb') as handle:\n",
    "    X_train = pickle.load(handle)  \n",
    "    \n",
    "with open(r'D:/Datasets/amazon_reviews/cdl_rating_matrix.pickle', 'rb') as handle2:\n",
    "    rating_matrix = pickle.load(handle2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix factorization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF():\n",
    "    def __init__(self , rating_matrix ):\n",
    "        self.num_u = rating_matrix.shape[0] #5551\n",
    "        self.num_v = rating_matrix.shape[1] #16980\n",
    "        \n",
    "        self.u_lambda = 100\n",
    "        self.v_lambda = 0.1\n",
    "        \n",
    "        self.k = 50 #latent維度\n",
    "        self.a = 1\n",
    "        self.b = 0.01\n",
    "        \n",
    "        self.R = np.mat(rating_matrix)\n",
    "        self.C = np.mat(np.ones(self.R.shape)) * self.b\n",
    "        self.C[np.where(self.R>0)] = self.a\n",
    "        \n",
    "        self.I_U = np.mat(np.eye(self.k) * self.u_lambda)\n",
    "        self.I_V = np.mat(np.eye(self.k) * self.v_lambda)\n",
    "        \n",
    "        self.U = np.mat(np.random.normal(0 , 1/self.u_lambda , size=(self.k,self.num_u)))\n",
    "        self.V = np.mat(np.random.normal(0 , 1/self.v_lambda , size=(self.k,self.num_v)))\n",
    "                        \n",
    "\n",
    "    def test(self):\n",
    "        print( ((U_cut*self.R[np.ravel(np.where(self.R[:,j]>0)[1]),j] + self.v_lambda * self.V_sdae[j])).shape)\n",
    "        \n",
    "    \n",
    "    def ALS(self , V_sdae):\n",
    "        self.V_sdae = np.mat(V_sdae)\n",
    "        \n",
    "        V_sq = self.V * self.V.T * self.b\n",
    "        for i in range(self.num_u):\n",
    "            idx_a = np.ravel(np.where(self.R[i,:]>0)[1])\n",
    "            V_cut = self.V[:,idx_a]\n",
    "            self.U[:,i] = np.linalg.pinv( V_sq+ V_cut * V_cut.T * (self.a-self.b) + self.I_U )*(V_cut*self.R[i,idx_a].T) #V_sq+V_cut*V_cut.T*a_m_b = VCV^T\n",
    "        \n",
    "        U_sq = self.U * self.U.T * self.b\n",
    "        for j in range(self.num_v):\n",
    "            idx_a = np.ravel(np.where(self.R[:,j]>0)[1])\n",
    "            U_cut = self.U[:,idx_a]\n",
    "            self.V[:,j] = np.linalg.pinv(U_sq+U_cut*U_cut.T*(self.a-self.b)+self.I_V)* (U_cut*self.R[idx_a,j] + self.v_lambda * np.resize(self.V_sdae[j],(self.k,1)))\n",
    "        \n",
    "        return self.U ,self.V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### masking noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(corruption_level, shape):\n",
    "    mask = np.random.binomial(1, 1 - corruption_level, shape)\n",
    "    return mask\n",
    "\n",
    "def add_noise(x , corruption_level ):\n",
    "    mask_ = mask(corruption_level , x.shape)\n",
    "    print(\"Mask shape: \" + str(mask_.shape))\n",
    "    x = np.multiply(x, mask_)\n",
    "    print(\"Noising completed..:\" + str(x.shape))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDL():\n",
    "    def __init__(self , rating_matrix , item_infomation_matrix):\n",
    "        # model參數設定\n",
    "        self.n_input = 10000\n",
    "        self.n_hidden1 = 500\n",
    "        self.n_hidden2 = 50\n",
    "        self.k = 50\n",
    "        \n",
    "        self.lambda_w = 1\n",
    "        self.lambda_n = 1\n",
    "        self.lambda_u = 1\n",
    "        self.lambda_v = 1\n",
    "        \n",
    "        self.drop_ratio = 0.1\n",
    "        self.learning_rate = 0.001\n",
    "        self.epochs = 500\n",
    "        self.batch_size = 32\n",
    "        \n",
    "        self.num_u = rating_matrix.shape[0]\n",
    "        self.num_v = rating_matrix.shape[1]\n",
    "        intializer = tf.variance_scaling_initializer()\n",
    "        \n",
    "        self.Weights = {\n",
    "            #'w1' : tf.Variable(tf.random_normal( [self.n_input , self.n_hidden1] , mean=0.0, stddev=1 / self.lambda_w )),\n",
    "            #'w2' : tf.Variable(tf.random_normal( [self.n_hidden1 , self.n_hidden2] , mean=0.0, stddev=1 / self.lambda_w )),\n",
    "            #'w3' : tf.Variable(tf.random_normal( [self.n_hidden2 , self.n_hidden1] , mean=0.0, stddev=1 / self.lambda_w )),\n",
    "            #'w4' : tf.Variable(tf.random_normal( [self.n_hidden1 , self.n_input] , mean=0.0, stddev=1 / self.lambda_w ))   \n",
    "            'w1' : tf.Variable(intializer([self.n_input, self.n_hidden1]), dtype=tf.float32),\n",
    "            'w2' : tf.Variable(intializer([self.n_hidden1, self.n_hidden2]), dtype=tf.float32),\n",
    "            'w3' : tf.Variable(intializer([self.n_hidden2, self.n_hidden1]), dtype=tf.float32),\n",
    "            'w4' : tf.Variable(intializer([self.n_hidden1, self.n_input]), dtype=tf.float32)   \n",
    "        }\n",
    "        self.Biases = {\n",
    "            #'b1' : tf.Variable(tf.random_normal( [self.n_hidden1] , mean=0.0, stddev=1 / self.lambda_w )),\n",
    "            #'b2' : tf.Variable(tf.random_normal( [self.n_hidden2] , mean=0.0, stddev=1 / self.lambda_w )),\n",
    "            #'b3' : tf.Variable(tf.random_normal( [self.n_hidden1] , mean=0.0, stddev=1 / self.lambda_w )),\n",
    "            #'b4' : tf.Variable(tf.random_normal( [self.n_input] , mean=0.0, stddev=1 / self.lambda_w ))\n",
    "            'b1' : tf.Variable(tf.zeros(self.n_hidden1)),\n",
    "            'b2' : tf.Variable(tf.zeros(self.n_hidden2)),\n",
    "            'b3' : tf.Variable(tf.zeros(self.n_hidden1)),\n",
    "            'b4' : tf.Variable(tf.zeros(self.n_input))\n",
    "        }\n",
    "        \n",
    "        self.item_infomation_matrix = item_infomation_matrix\n",
    "        self.rating_matrix = rating_matrix\n",
    "    \n",
    "        self.build_model()\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    def encoder(self , x , drop_ratio):\n",
    "        w1 = self.Weights['w1']\n",
    "        b1 = self.Biases['b1']\n",
    "        L1 = tf.nn.relu( tf.matmul(x,w1) + b1 )\n",
    "        L1 = tf.nn.dropout( L1 , keep_prob= 1 - drop_ratio )\n",
    "        \n",
    "        w2 = self.Weights['w2']\n",
    "        b2 = self.Biases['b2']\n",
    "        L2 = tf.nn.relu( tf.matmul(L1,w2) + b2 )\n",
    "        L2 = tf.nn.dropout(L2 , keep_prob= 1 - drop_ratio)\n",
    "        \n",
    "        return L2\n",
    "    \n",
    "    def decoder(self , x , drop_ratio):\n",
    "        w3 = self.Weights['w3']\n",
    "        b3 = self.Biases['b3']\n",
    "        L3 = tf.nn.relu(tf.matmul(x,w3) + b3)\n",
    "        L3 = tf.nn.dropout(L3 , keep_prob= 1 - drop_ratio)\n",
    "\n",
    "        w4 = self.Weights['w4']\n",
    "        b4 = self.Biases['b4']\n",
    "        L4 = tf.nn.relu(tf.matmul(L3,w4) + b4)\n",
    "        L4 = tf.nn.dropout(L4 , keep_prob= 1 - drop_ratio)\n",
    "\n",
    "        return L4\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.model_X_0 = tf.placeholder(tf.float32 , shape=(None , self.n_input))\n",
    "        self.model_X_c = tf.placeholder(tf.float32 , shape=(None , self.n_input))\n",
    "        self.model_V = tf.placeholder(tf.float32 , shape=(None , self.k))\n",
    "        self.model_drop_ratio = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self.V_sdae = self.encoder( self.model_X_0 , self.model_drop_ratio )\n",
    "        self.y_pred = self.decoder( self.V_sdae , self.model_drop_ratio )\n",
    "        \n",
    "        self.Regularization = tf.reduce_sum([tf.nn.l2_loss(w) + tf.nn.l2_loss(b) \n",
    "                                             for w,b in zip(self.Weights.values() , self.Biases.values())])\n",
    "        loss_r =1/2 * self.lambda_w * self.Regularization\n",
    "        loss_a =1/2 * self.lambda_n * tf.reduce_sum(tf.pow( self.model_X_c - self.y_pred , 2 ))\n",
    "        loss_v =1/2 * self.lambda_v * tf.reduce_sum(tf.pow( self.model_V - self.V_sdae , 2 ))\n",
    "        \n",
    "        self.Loss = loss_r + loss_a + loss_v\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.Loss)\n",
    "    \n",
    "    def training(self):\n",
    "        #np.random.shuffle(self.item_infomation_matrix) #random index of train data\n",
    "        \n",
    "        self.item_infomation_matrix_noise = add_noise(self.item_infomation_matrix , 0.3)\n",
    "        \n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        mf = MF(self.rating_matrix)\n",
    "        \n",
    "        for epoch in range(0, self.epochs):\n",
    "            print(\"%d / %d\"%(epoch+1 , self.epochs))\n",
    "            \n",
    "            V_sdae = sess.run(self.V_sdae , feed_dict={self.model_X_0 : self.item_infomation_matrix_noise , self.model_drop_ratio : 0.1})\n",
    "            \n",
    "            U , V = mf.ALS(V_sdae)\n",
    "            V = np.resize(V, (self.num_v , 50))\n",
    "            \n",
    "            for i in range(0 , self.item_infomation_matrix.shape[0] , self.batch_size):\n",
    "                X_train_batch = self.item_infomation_matrix_noise[i:i+self.batch_size]\n",
    "                y_train_batch = self.item_infomation_matrix[i:i+self.batch_size]\n",
    "                V_batch = V[i:i+self.batch_size]\n",
    "                \n",
    "                _ , my_loss = sess.run([self.optimizer, self.Loss] , feed_dict={self.model_X_0 :X_train_batch , self.model_X_c : y_train_batch , self.model_V:V_batch, self.model_drop_ratio : 0.1})\n",
    "            \n",
    "            print(\"EPOCH %i LOSS %d\" % (epoch, my_loss))\n",
    "            \n",
    "            if epoch % 50 == 0:\n",
    "                os.mkdir('./models/%s/' % epoch)\n",
    "                self.saver.save(sess, './models/%s/model_.ckpt' % epoch)\n",
    "        \n",
    "        sess.close()\n",
    "        return U, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10666, 10000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_infomation_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24280, 10666)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask shape: (10666, 10000)\n",
      "Noising completed..:(10666, 10000)\n",
      "1 / 500\n",
      "EPOCH 0 LOSS 38256\n",
      "2 / 500\n",
      "EPOCH 1 LOSS 37839\n",
      "3 / 500\n",
      "EPOCH 2 LOSS 45189\n",
      "4 / 500\n",
      "EPOCH 3 LOSS 38831\n",
      "5 / 500\n",
      "EPOCH 4 LOSS 45071\n",
      "6 / 500\n",
      "EPOCH 5 LOSS 47140\n",
      "7 / 500\n",
      "EPOCH 6 LOSS 41313\n",
      "8 / 500\n",
      "EPOCH 7 LOSS 51621\n",
      "9 / 500\n",
      "EPOCH 8 LOSS 41407\n",
      "10 / 500\n",
      "EPOCH 9 LOSS 41800\n",
      "11 / 500\n",
      "EPOCH 10 LOSS 36958\n",
      "12 / 500\n",
      "EPOCH 11 LOSS 44572\n",
      "13 / 500\n",
      "EPOCH 12 LOSS 43631\n",
      "14 / 500\n",
      "EPOCH 13 LOSS 41954\n",
      "15 / 500\n",
      "EPOCH 14 LOSS 41988\n",
      "16 / 500\n",
      "EPOCH 15 LOSS 38905\n",
      "17 / 500\n",
      "EPOCH 16 LOSS 41959\n",
      "18 / 500\n",
      "EPOCH 17 LOSS 35495\n",
      "19 / 500\n",
      "EPOCH 18 LOSS 36717\n",
      "20 / 500\n",
      "EPOCH 19 LOSS 38856\n",
      "21 / 500\n",
      "EPOCH 20 LOSS 36139\n",
      "22 / 500\n",
      "EPOCH 21 LOSS 48009\n",
      "23 / 500\n",
      "EPOCH 22 LOSS 42087\n",
      "24 / 500\n",
      "EPOCH 23 LOSS 41003\n",
      "25 / 500\n",
      "EPOCH 24 LOSS 38418\n",
      "26 / 500\n",
      "EPOCH 25 LOSS 39123\n",
      "27 / 500\n",
      "EPOCH 26 LOSS 38324\n",
      "28 / 500\n",
      "EPOCH 27 LOSS 41622\n",
      "29 / 500\n",
      "EPOCH 28 LOSS 36707\n",
      "30 / 500\n",
      "EPOCH 29 LOSS 34216\n",
      "31 / 500\n",
      "EPOCH 30 LOSS 48535\n",
      "32 / 500\n",
      "EPOCH 31 LOSS 37472\n",
      "33 / 500\n",
      "EPOCH 32 LOSS 35541\n",
      "34 / 500\n",
      "EPOCH 33 LOSS 39322\n",
      "35 / 500\n",
      "EPOCH 34 LOSS 36739\n",
      "36 / 500\n",
      "EPOCH 35 LOSS 47666\n",
      "37 / 500\n",
      "EPOCH 36 LOSS 42591\n",
      "38 / 500\n",
      "EPOCH 37 LOSS 34285\n",
      "39 / 500\n",
      "EPOCH 38 LOSS 37684\n",
      "40 / 500\n",
      "EPOCH 39 LOSS 33505\n",
      "41 / 500\n",
      "EPOCH 40 LOSS 36765\n",
      "42 / 500\n",
      "EPOCH 41 LOSS 38240\n",
      "43 / 500\n",
      "EPOCH 42 LOSS 33718\n",
      "44 / 500\n",
      "EPOCH 43 LOSS 34698\n",
      "45 / 500\n",
      "EPOCH 44 LOSS 34628\n",
      "46 / 500\n",
      "EPOCH 45 LOSS 39904\n",
      "47 / 500\n",
      "EPOCH 46 LOSS 42711\n",
      "48 / 500\n",
      "EPOCH 47 LOSS 42695\n",
      "49 / 500\n",
      "EPOCH 48 LOSS 48934\n",
      "50 / 500\n",
      "EPOCH 49 LOSS 37732\n",
      "51 / 500\n",
      "EPOCH 50 LOSS 31897\n",
      "52 / 500\n",
      "EPOCH 51 LOSS 33702\n",
      "53 / 500\n",
      "EPOCH 52 LOSS 45910\n",
      "54 / 500\n",
      "EPOCH 53 LOSS 40721\n",
      "55 / 500\n",
      "EPOCH 54 LOSS 38021\n",
      "56 / 500\n",
      "EPOCH 55 LOSS 37796\n",
      "57 / 500\n",
      "EPOCH 56 LOSS 33116\n",
      "58 / 500\n",
      "EPOCH 57 LOSS 36921\n",
      "59 / 500\n",
      "EPOCH 58 LOSS 37273\n",
      "60 / 500\n",
      "EPOCH 59 LOSS 40435\n",
      "61 / 500\n",
      "EPOCH 60 LOSS 58951\n",
      "62 / 500\n",
      "EPOCH 61 LOSS 48394\n",
      "63 / 500\n",
      "EPOCH 62 LOSS 36664\n",
      "64 / 500\n",
      "EPOCH 63 LOSS 36260\n",
      "65 / 500\n",
      "EPOCH 64 LOSS 33188\n",
      "66 / 500\n",
      "EPOCH 65 LOSS 38442\n",
      "67 / 500\n",
      "EPOCH 66 LOSS 40202\n",
      "68 / 500\n",
      "EPOCH 67 LOSS 51411\n",
      "69 / 500\n",
      "EPOCH 68 LOSS 36006\n",
      "70 / 500\n",
      "EPOCH 69 LOSS 34883\n",
      "71 / 500\n",
      "EPOCH 70 LOSS 33815\n",
      "72 / 500\n",
      "EPOCH 71 LOSS 38325\n",
      "73 / 500\n",
      "EPOCH 72 LOSS 36805\n",
      "74 / 500\n",
      "EPOCH 73 LOSS 38756\n",
      "75 / 500\n",
      "EPOCH 74 LOSS 39072\n",
      "76 / 500\n",
      "EPOCH 75 LOSS 33225\n",
      "77 / 500\n",
      "EPOCH 76 LOSS 35822\n",
      "78 / 500\n",
      "EPOCH 77 LOSS 39344\n",
      "79 / 500\n",
      "EPOCH 78 LOSS 44476\n",
      "80 / 500\n",
      "EPOCH 79 LOSS 42804\n",
      "81 / 500\n",
      "EPOCH 80 LOSS 34158\n",
      "82 / 500\n",
      "EPOCH 81 LOSS 35537\n",
      "83 / 500\n",
      "EPOCH 82 LOSS 35954\n",
      "84 / 500\n",
      "EPOCH 83 LOSS 39624\n",
      "85 / 500\n",
      "EPOCH 84 LOSS 36554\n",
      "86 / 500\n",
      "EPOCH 85 LOSS 44562\n",
      "87 / 500\n",
      "EPOCH 86 LOSS 41500\n",
      "88 / 500\n",
      "EPOCH 87 LOSS 33496\n",
      "89 / 500\n",
      "EPOCH 88 LOSS 36801\n",
      "90 / 500\n",
      "EPOCH 89 LOSS 43544\n",
      "91 / 500\n",
      "EPOCH 90 LOSS 31976\n",
      "92 / 500\n",
      "EPOCH 91 LOSS 39836\n",
      "93 / 500\n",
      "EPOCH 92 LOSS 40601\n",
      "94 / 500\n",
      "EPOCH 93 LOSS 36516\n",
      "95 / 500\n",
      "EPOCH 94 LOSS 34106\n",
      "96 / 500\n",
      "EPOCH 95 LOSS 39326\n",
      "97 / 500\n",
      "EPOCH 96 LOSS 34913\n",
      "98 / 500\n",
      "EPOCH 97 LOSS 32304\n",
      "99 / 500\n",
      "EPOCH 98 LOSS 37747\n",
      "100 / 500\n",
      "EPOCH 99 LOSS 38334\n",
      "101 / 500\n",
      "EPOCH 100 LOSS 38387\n",
      "102 / 500\n",
      "EPOCH 101 LOSS 38786\n",
      "103 / 500\n",
      "EPOCH 102 LOSS 42423\n",
      "104 / 500\n",
      "EPOCH 103 LOSS 33670\n",
      "105 / 500\n",
      "EPOCH 104 LOSS 44097\n",
      "106 / 500\n",
      "EPOCH 105 LOSS 37337\n",
      "107 / 500\n",
      "EPOCH 106 LOSS 37055\n",
      "108 / 500\n",
      "EPOCH 107 LOSS 34609\n",
      "109 / 500\n",
      "EPOCH 108 LOSS 33966\n",
      "110 / 500\n",
      "EPOCH 109 LOSS 44584\n",
      "111 / 500\n",
      "EPOCH 110 LOSS 32196\n",
      "112 / 500\n",
      "EPOCH 111 LOSS 48634\n",
      "113 / 500\n",
      "EPOCH 112 LOSS 39945\n",
      "114 / 500\n",
      "EPOCH 113 LOSS 36218\n",
      "115 / 500\n",
      "EPOCH 114 LOSS 42622\n",
      "116 / 500\n",
      "EPOCH 115 LOSS 33605\n",
      "117 / 500\n",
      "EPOCH 116 LOSS 43195\n",
      "118 / 500\n",
      "EPOCH 117 LOSS 41437\n",
      "119 / 500\n",
      "EPOCH 118 LOSS 33846\n",
      "120 / 500\n",
      "EPOCH 119 LOSS 33715\n",
      "121 / 500\n",
      "EPOCH 120 LOSS 40721\n",
      "122 / 500\n",
      "EPOCH 121 LOSS 41043\n",
      "123 / 500\n",
      "EPOCH 122 LOSS 34465\n",
      "124 / 500\n",
      "EPOCH 123 LOSS 36609\n",
      "125 / 500\n",
      "EPOCH 124 LOSS 35229\n",
      "126 / 500\n",
      "EPOCH 125 LOSS 41319\n",
      "127 / 500\n",
      "EPOCH 126 LOSS 32963\n",
      "128 / 500\n",
      "EPOCH 127 LOSS 33986\n",
      "129 / 500\n",
      "EPOCH 128 LOSS 35417\n",
      "130 / 500\n",
      "EPOCH 129 LOSS 46044\n",
      "131 / 500\n",
      "EPOCH 130 LOSS 35466\n",
      "132 / 500\n",
      "EPOCH 131 LOSS 32782\n",
      "133 / 500\n",
      "EPOCH 132 LOSS 32656\n",
      "134 / 500\n",
      "EPOCH 133 LOSS 34321\n",
      "135 / 500\n",
      "EPOCH 134 LOSS 33340\n",
      "136 / 500\n",
      "EPOCH 135 LOSS 41010\n",
      "137 / 500\n",
      "EPOCH 136 LOSS 37947\n",
      "138 / 500\n",
      "EPOCH 137 LOSS 42062\n",
      "139 / 500\n",
      "EPOCH 138 LOSS 40082\n",
      "140 / 500\n",
      "EPOCH 139 LOSS 40842\n",
      "141 / 500\n",
      "EPOCH 140 LOSS 33189\n",
      "142 / 500\n",
      "EPOCH 141 LOSS 34318\n",
      "143 / 500\n",
      "EPOCH 142 LOSS 37441\n",
      "144 / 500\n",
      "EPOCH 143 LOSS 41717\n",
      "145 / 500\n",
      "EPOCH 144 LOSS 30724\n",
      "146 / 500\n",
      "EPOCH 145 LOSS 35566\n",
      "147 / 500\n",
      "EPOCH 146 LOSS 29903\n",
      "148 / 500\n",
      "EPOCH 147 LOSS 35228\n",
      "149 / 500\n",
      "EPOCH 148 LOSS 31784\n",
      "150 / 500\n",
      "EPOCH 149 LOSS 45249\n",
      "151 / 500\n",
      "EPOCH 150 LOSS 40014\n",
      "152 / 500\n",
      "EPOCH 151 LOSS 34489\n",
      "153 / 500\n",
      "EPOCH 152 LOSS 31730\n",
      "154 / 500\n",
      "EPOCH 153 LOSS 32292\n",
      "155 / 500\n",
      "EPOCH 154 LOSS 30479\n",
      "156 / 500\n",
      "EPOCH 155 LOSS 30720\n",
      "157 / 500\n",
      "EPOCH 156 LOSS 33310\n",
      "158 / 500\n",
      "EPOCH 157 LOSS 35661\n",
      "159 / 500\n",
      "EPOCH 158 LOSS 37957\n",
      "160 / 500\n",
      "EPOCH 159 LOSS 41527\n",
      "161 / 500\n",
      "EPOCH 160 LOSS 28873\n",
      "162 / 500\n",
      "EPOCH 161 LOSS 32906\n",
      "163 / 500\n",
      "EPOCH 162 LOSS 36157\n",
      "164 / 500\n",
      "EPOCH 163 LOSS 36085\n",
      "165 / 500\n",
      "EPOCH 164 LOSS 34945\n",
      "166 / 500\n",
      "EPOCH 165 LOSS 47828\n",
      "167 / 500\n",
      "EPOCH 166 LOSS 34213\n",
      "168 / 500\n",
      "EPOCH 167 LOSS 38647\n",
      "169 / 500\n",
      "EPOCH 168 LOSS 37347\n",
      "170 / 500\n",
      "EPOCH 169 LOSS 36798\n",
      "171 / 500\n",
      "EPOCH 170 LOSS 29600\n",
      "172 / 500\n",
      "EPOCH 171 LOSS 36274\n",
      "173 / 500\n",
      "EPOCH 172 LOSS 32715\n",
      "174 / 500\n",
      "EPOCH 173 LOSS 46386\n",
      "175 / 500\n",
      "EPOCH 174 LOSS 31750\n",
      "176 / 500\n",
      "EPOCH 175 LOSS 46792\n",
      "177 / 500\n",
      "EPOCH 176 LOSS 36895\n",
      "178 / 500\n",
      "EPOCH 177 LOSS 34215\n",
      "179 / 500\n",
      "EPOCH 178 LOSS 30270\n",
      "180 / 500\n",
      "EPOCH 179 LOSS 30546\n",
      "181 / 500\n",
      "EPOCH 180 LOSS 34045\n",
      "182 / 500\n",
      "EPOCH 181 LOSS 33231\n",
      "183 / 500\n",
      "EPOCH 182 LOSS 29351\n",
      "184 / 500\n",
      "EPOCH 183 LOSS 34253\n",
      "185 / 500\n",
      "EPOCH 184 LOSS 34345\n",
      "186 / 500\n",
      "EPOCH 185 LOSS 44763\n",
      "187 / 500\n",
      "EPOCH 186 LOSS 28764\n",
      "188 / 500\n",
      "EPOCH 187 LOSS 32778\n",
      "189 / 500\n",
      "EPOCH 188 LOSS 30808\n",
      "190 / 500\n",
      "EPOCH 189 LOSS 32890\n",
      "191 / 500\n",
      "EPOCH 190 LOSS 36465\n",
      "192 / 500\n",
      "EPOCH 191 LOSS 34690\n",
      "193 / 500\n",
      "EPOCH 192 LOSS 34893\n",
      "194 / 500\n",
      "EPOCH 193 LOSS 28879\n",
      "195 / 500\n",
      "EPOCH 194 LOSS 43251\n",
      "196 / 500\n",
      "EPOCH 195 LOSS 40454\n",
      "197 / 500\n",
      "EPOCH 196 LOSS 31435\n",
      "198 / 500\n",
      "EPOCH 197 LOSS 39264\n",
      "199 / 500\n",
      "EPOCH 198 LOSS 45540\n",
      "200 / 500\n",
      "EPOCH 199 LOSS 34099\n",
      "201 / 500\n",
      "EPOCH 200 LOSS 32546\n",
      "202 / 500\n",
      "EPOCH 201 LOSS 34675\n",
      "203 / 500\n",
      "EPOCH 202 LOSS 33786\n",
      "204 / 500\n",
      "EPOCH 203 LOSS 37527\n",
      "205 / 500\n",
      "EPOCH 204 LOSS 31090\n",
      "206 / 500\n",
      "EPOCH 205 LOSS 34784\n",
      "207 / 500\n",
      "EPOCH 206 LOSS 41689\n",
      "208 / 500\n",
      "EPOCH 207 LOSS 48295\n",
      "209 / 500\n",
      "EPOCH 208 LOSS 38417\n",
      "210 / 500\n",
      "EPOCH 209 LOSS 36914\n",
      "211 / 500\n",
      "EPOCH 210 LOSS 36208\n",
      "212 / 500\n",
      "EPOCH 211 LOSS 37227\n",
      "213 / 500\n",
      "EPOCH 212 LOSS 38076\n",
      "214 / 500\n",
      "EPOCH 213 LOSS 35963\n",
      "215 / 500\n",
      "EPOCH 214 LOSS 44092\n",
      "216 / 500\n",
      "EPOCH 215 LOSS 29127\n",
      "217 / 500\n",
      "EPOCH 216 LOSS 34772\n",
      "218 / 500\n",
      "EPOCH 217 LOSS 40055\n",
      "219 / 500\n",
      "EPOCH 218 LOSS 45531\n",
      "220 / 500\n",
      "EPOCH 219 LOSS 45262\n",
      "221 / 500\n",
      "EPOCH 220 LOSS 32285\n",
      "222 / 500\n",
      "EPOCH 221 LOSS 32330\n",
      "223 / 500\n",
      "EPOCH 222 LOSS 28752\n",
      "224 / 500\n",
      "EPOCH 223 LOSS 39032\n",
      "225 / 500\n",
      "EPOCH 224 LOSS 34082\n",
      "226 / 500\n",
      "EPOCH 225 LOSS 32037\n",
      "227 / 500\n",
      "EPOCH 226 LOSS 36749\n",
      "228 / 500\n",
      "EPOCH 227 LOSS 30170\n",
      "229 / 500\n",
      "EPOCH 228 LOSS 41911\n",
      "230 / 500\n",
      "EPOCH 229 LOSS 34933\n",
      "231 / 500\n",
      "EPOCH 230 LOSS 34111\n",
      "232 / 500\n",
      "EPOCH 231 LOSS 31201\n",
      "233 / 500\n",
      "EPOCH 232 LOSS 41093\n",
      "234 / 500\n",
      "EPOCH 233 LOSS 39113\n",
      "235 / 500\n",
      "EPOCH 234 LOSS 41902\n",
      "236 / 500\n",
      "EPOCH 235 LOSS 37628\n",
      "237 / 500\n",
      "EPOCH 236 LOSS 31903\n",
      "238 / 500\n",
      "EPOCH 237 LOSS 33501\n",
      "239 / 500\n",
      "EPOCH 238 LOSS 31483\n",
      "240 / 500\n",
      "EPOCH 239 LOSS 34381\n",
      "241 / 500\n",
      "EPOCH 240 LOSS 29817\n",
      "242 / 500\n",
      "EPOCH 241 LOSS 38215\n",
      "243 / 500\n",
      "EPOCH 242 LOSS 35364\n",
      "244 / 500\n",
      "EPOCH 243 LOSS 37506\n",
      "245 / 500\n",
      "EPOCH 244 LOSS 36073\n",
      "246 / 500\n",
      "EPOCH 245 LOSS 42746\n",
      "247 / 500\n",
      "EPOCH 246 LOSS 41551\n",
      "248 / 500\n",
      "EPOCH 247 LOSS 32461\n",
      "249 / 500\n",
      "EPOCH 248 LOSS 44338\n",
      "250 / 500\n",
      "EPOCH 249 LOSS 33779\n",
      "251 / 500\n",
      "EPOCH 250 LOSS 31263\n",
      "WARNING:tensorflow:From /home/neopux/miniconda3/envs/exmc/lib/python3.7/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "252 / 500\n",
      "EPOCH 251 LOSS 36088\n",
      "253 / 500\n",
      "EPOCH 252 LOSS 31185\n",
      "254 / 500\n",
      "EPOCH 253 LOSS 36909\n",
      "255 / 500\n",
      "EPOCH 254 LOSS 30981\n",
      "256 / 500\n",
      "EPOCH 255 LOSS 39384\n",
      "257 / 500\n",
      "EPOCH 256 LOSS 34347\n",
      "258 / 500\n",
      "EPOCH 257 LOSS 38523\n",
      "259 / 500\n",
      "EPOCH 258 LOSS 31423\n",
      "260 / 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 259 LOSS 39885\n",
      "261 / 500\n",
      "EPOCH 260 LOSS 41989\n",
      "262 / 500\n",
      "EPOCH 261 LOSS 40323\n",
      "263 / 500\n",
      "EPOCH 262 LOSS 37295\n",
      "264 / 500\n",
      "EPOCH 263 LOSS 41465\n",
      "265 / 500\n",
      "EPOCH 264 LOSS 45385\n",
      "266 / 500\n",
      "EPOCH 265 LOSS 31862\n",
      "267 / 500\n",
      "EPOCH 266 LOSS 35395\n",
      "268 / 500\n",
      "EPOCH 267 LOSS 36998\n",
      "269 / 500\n",
      "EPOCH 268 LOSS 34485\n",
      "270 / 500\n",
      "EPOCH 269 LOSS 31187\n",
      "271 / 500\n",
      "EPOCH 270 LOSS 30054\n",
      "272 / 500\n",
      "EPOCH 271 LOSS 36077\n",
      "273 / 500\n",
      "EPOCH 272 LOSS 34100\n",
      "274 / 500\n",
      "EPOCH 273 LOSS 37411\n",
      "275 / 500\n",
      "EPOCH 274 LOSS 31523\n",
      "276 / 500\n",
      "EPOCH 275 LOSS 32512\n",
      "277 / 500\n",
      "EPOCH 276 LOSS 34132\n",
      "278 / 500\n",
      "EPOCH 277 LOSS 29298\n",
      "279 / 500\n",
      "EPOCH 278 LOSS 37686\n",
      "280 / 500\n",
      "EPOCH 279 LOSS 30616\n",
      "281 / 500\n",
      "EPOCH 280 LOSS 38028\n",
      "282 / 500\n",
      "EPOCH 281 LOSS 35323\n",
      "283 / 500\n",
      "EPOCH 282 LOSS 38205\n",
      "284 / 500\n",
      "EPOCH 283 LOSS 38449\n",
      "285 / 500\n",
      "EPOCH 284 LOSS 33003\n",
      "286 / 500\n",
      "EPOCH 285 LOSS 47594\n",
      "287 / 500\n",
      "EPOCH 286 LOSS 36285\n",
      "288 / 500\n",
      "EPOCH 287 LOSS 41134\n",
      "289 / 500\n",
      "EPOCH 288 LOSS 29015\n",
      "290 / 500\n",
      "EPOCH 289 LOSS 29896\n",
      "291 / 500\n",
      "EPOCH 290 LOSS 34182\n",
      "292 / 500\n",
      "EPOCH 291 LOSS 39943\n",
      "293 / 500\n",
      "EPOCH 292 LOSS 35314\n",
      "294 / 500\n",
      "EPOCH 293 LOSS 36578\n",
      "295 / 500\n",
      "EPOCH 294 LOSS 35790\n",
      "296 / 500\n",
      "EPOCH 295 LOSS 28918\n",
      "297 / 500\n",
      "EPOCH 296 LOSS 36078\n",
      "298 / 500\n",
      "EPOCH 297 LOSS 30755\n",
      "299 / 500\n",
      "EPOCH 298 LOSS 33404\n",
      "300 / 500\n",
      "EPOCH 299 LOSS 30939\n",
      "301 / 500\n",
      "EPOCH 300 LOSS 31416\n",
      "302 / 500\n",
      "EPOCH 301 LOSS 29722\n",
      "303 / 500\n",
      "EPOCH 302 LOSS 37527\n",
      "304 / 500\n",
      "EPOCH 303 LOSS 37876\n",
      "305 / 500\n",
      "EPOCH 304 LOSS 35718\n",
      "306 / 500\n",
      "EPOCH 305 LOSS 30712\n",
      "307 / 500\n",
      "EPOCH 306 LOSS 33986\n",
      "308 / 500\n",
      "EPOCH 307 LOSS 30316\n",
      "309 / 500\n",
      "EPOCH 308 LOSS 43844\n",
      "310 / 500\n",
      "EPOCH 309 LOSS 31347\n",
      "311 / 500\n",
      "EPOCH 310 LOSS 30604\n",
      "312 / 500\n",
      "EPOCH 311 LOSS 35873\n",
      "313 / 500\n",
      "EPOCH 312 LOSS 34920\n",
      "314 / 500\n",
      "EPOCH 313 LOSS 33486\n",
      "315 / 500\n",
      "EPOCH 314 LOSS 30841\n",
      "316 / 500\n",
      "EPOCH 315 LOSS 31251\n",
      "317 / 500\n",
      "EPOCH 316 LOSS 40450\n",
      "318 / 500\n",
      "EPOCH 317 LOSS 36448\n",
      "319 / 500\n",
      "EPOCH 318 LOSS 32215\n",
      "320 / 500\n",
      "EPOCH 319 LOSS 42443\n",
      "321 / 500\n",
      "EPOCH 320 LOSS 39497\n",
      "322 / 500\n",
      "EPOCH 321 LOSS 41526\n",
      "323 / 500\n",
      "EPOCH 322 LOSS 37957\n",
      "324 / 500\n",
      "EPOCH 323 LOSS 31979\n",
      "325 / 500\n",
      "EPOCH 324 LOSS 33057\n",
      "326 / 500\n",
      "EPOCH 325 LOSS 36271\n",
      "327 / 500\n",
      "EPOCH 326 LOSS 41547\n",
      "328 / 500\n",
      "EPOCH 327 LOSS 33627\n",
      "329 / 500\n",
      "EPOCH 328 LOSS 37556\n",
      "330 / 500\n",
      "EPOCH 329 LOSS 30075\n",
      "331 / 500\n",
      "EPOCH 330 LOSS 34438\n",
      "332 / 500\n",
      "EPOCH 331 LOSS 39120\n",
      "333 / 500\n",
      "EPOCH 332 LOSS 48273\n",
      "334 / 500\n",
      "EPOCH 333 LOSS 31221\n",
      "335 / 500\n",
      "EPOCH 334 LOSS 29063\n",
      "336 / 500\n",
      "EPOCH 335 LOSS 38019\n",
      "337 / 500\n",
      "EPOCH 336 LOSS 34629\n",
      "338 / 500\n",
      "EPOCH 337 LOSS 38140\n",
      "339 / 500\n",
      "EPOCH 338 LOSS 33355\n",
      "340 / 500\n",
      "EPOCH 339 LOSS 34935\n",
      "341 / 500\n",
      "EPOCH 340 LOSS 32045\n",
      "342 / 500\n",
      "EPOCH 341 LOSS 32186\n",
      "343 / 500\n",
      "EPOCH 342 LOSS 38245\n",
      "344 / 500\n",
      "EPOCH 343 LOSS 36370\n",
      "345 / 500\n",
      "EPOCH 344 LOSS 40748\n",
      "346 / 500\n",
      "EPOCH 345 LOSS 34039\n",
      "347 / 500\n",
      "EPOCH 346 LOSS 36556\n",
      "348 / 500\n",
      "EPOCH 347 LOSS 35572\n",
      "349 / 500\n",
      "EPOCH 348 LOSS 30729\n",
      "350 / 500\n",
      "EPOCH 349 LOSS 32272\n",
      "351 / 500\n",
      "EPOCH 350 LOSS 49211\n",
      "352 / 500\n",
      "EPOCH 351 LOSS 33217\n",
      "353 / 500\n",
      "EPOCH 352 LOSS 36344\n",
      "354 / 500\n",
      "EPOCH 353 LOSS 39128\n",
      "355 / 500\n",
      "EPOCH 354 LOSS 36773\n",
      "356 / 500\n",
      "EPOCH 355 LOSS 41074\n",
      "357 / 500\n",
      "EPOCH 356 LOSS 31618\n",
      "358 / 500\n",
      "EPOCH 357 LOSS 35455\n",
      "359 / 500\n",
      "EPOCH 358 LOSS 33015\n",
      "360 / 500\n",
      "EPOCH 359 LOSS 37146\n",
      "361 / 500\n",
      "EPOCH 360 LOSS 35324\n",
      "362 / 500\n",
      "EPOCH 361 LOSS 31887\n",
      "363 / 500\n",
      "EPOCH 362 LOSS 34317\n",
      "364 / 500\n",
      "EPOCH 363 LOSS 40566\n",
      "365 / 500\n",
      "EPOCH 364 LOSS 32863\n",
      "366 / 500\n",
      "EPOCH 365 LOSS 44679\n",
      "367 / 500\n",
      "EPOCH 366 LOSS 37505\n",
      "368 / 500\n",
      "EPOCH 367 LOSS 32031\n",
      "369 / 500\n",
      "EPOCH 368 LOSS 39840\n",
      "370 / 500\n",
      "EPOCH 369 LOSS 38138\n",
      "371 / 500\n",
      "EPOCH 370 LOSS 35702\n",
      "372 / 500\n",
      "EPOCH 371 LOSS 54878\n",
      "373 / 500\n",
      "EPOCH 372 LOSS 41257\n",
      "374 / 500\n",
      "EPOCH 373 LOSS 36011\n",
      "375 / 500\n",
      "EPOCH 374 LOSS 34388\n",
      "376 / 500\n",
      "EPOCH 375 LOSS 37108\n",
      "377 / 500\n",
      "EPOCH 376 LOSS 32596\n",
      "378 / 500\n",
      "EPOCH 377 LOSS 34983\n",
      "379 / 500\n",
      "EPOCH 378 LOSS 39463\n",
      "380 / 500\n",
      "EPOCH 379 LOSS 42339\n",
      "381 / 500\n",
      "EPOCH 380 LOSS 36116\n",
      "382 / 500\n",
      "EPOCH 381 LOSS 36780\n",
      "383 / 500\n",
      "EPOCH 382 LOSS 30754\n",
      "384 / 500\n",
      "EPOCH 383 LOSS 40220\n",
      "385 / 500\n",
      "EPOCH 384 LOSS 41343\n",
      "386 / 500\n",
      "EPOCH 385 LOSS 42251\n",
      "387 / 500\n",
      "EPOCH 386 LOSS 41636\n",
      "388 / 500\n",
      "EPOCH 387 LOSS 40251\n",
      "389 / 500\n",
      "EPOCH 388 LOSS 34505\n",
      "390 / 500\n",
      "EPOCH 389 LOSS 31333\n",
      "391 / 500\n",
      "EPOCH 390 LOSS 36149\n",
      "392 / 500\n",
      "EPOCH 391 LOSS 44524\n",
      "393 / 500\n",
      "EPOCH 392 LOSS 36309\n",
      "394 / 500\n",
      "EPOCH 393 LOSS 39317\n",
      "395 / 500\n",
      "EPOCH 394 LOSS 33571\n",
      "396 / 500\n",
      "EPOCH 395 LOSS 32294\n",
      "397 / 500\n",
      "EPOCH 396 LOSS 30902\n",
      "398 / 500\n",
      "EPOCH 397 LOSS 37918\n",
      "399 / 500\n",
      "EPOCH 398 LOSS 45377\n",
      "400 / 500\n",
      "EPOCH 399 LOSS 43198\n",
      "401 / 500\n",
      "EPOCH 400 LOSS 32847\n",
      "402 / 500\n",
      "EPOCH 401 LOSS 37259\n",
      "403 / 500\n",
      "EPOCH 402 LOSS 31473\n",
      "404 / 500\n",
      "EPOCH 403 LOSS 37433\n",
      "405 / 500\n",
      "EPOCH 404 LOSS 40291\n",
      "406 / 500\n",
      "EPOCH 405 LOSS 35187\n",
      "407 / 500\n",
      "EPOCH 406 LOSS 36287\n",
      "408 / 500\n",
      "EPOCH 407 LOSS 36297\n",
      "409 / 500\n",
      "EPOCH 408 LOSS 33055\n",
      "410 / 500\n",
      "EPOCH 409 LOSS 32862\n",
      "411 / 500\n",
      "EPOCH 410 LOSS 47508\n",
      "412 / 500\n",
      "EPOCH 411 LOSS 41286\n",
      "413 / 500\n",
      "EPOCH 412 LOSS 37804\n",
      "414 / 500\n",
      "EPOCH 413 LOSS 33040\n",
      "415 / 500\n",
      "EPOCH 414 LOSS 36287\n",
      "416 / 500\n",
      "EPOCH 415 LOSS 32627\n",
      "417 / 500\n",
      "EPOCH 416 LOSS 35492\n",
      "418 / 500\n",
      "EPOCH 417 LOSS 38262\n",
      "419 / 500\n",
      "EPOCH 418 LOSS 37574\n",
      "420 / 500\n",
      "EPOCH 419 LOSS 35686\n",
      "421 / 500\n",
      "EPOCH 420 LOSS 35141\n",
      "422 / 500\n",
      "EPOCH 421 LOSS 34835\n",
      "423 / 500\n",
      "EPOCH 422 LOSS 31915\n",
      "424 / 500\n",
      "EPOCH 423 LOSS 36779\n",
      "425 / 500\n",
      "EPOCH 424 LOSS 35297\n",
      "426 / 500\n",
      "EPOCH 425 LOSS 39425\n",
      "427 / 500\n",
      "EPOCH 426 LOSS 30675\n",
      "428 / 500\n",
      "EPOCH 427 LOSS 33344\n",
      "429 / 500\n",
      "EPOCH 428 LOSS 36603\n",
      "430 / 500\n",
      "EPOCH 429 LOSS 32034\n",
      "431 / 500\n",
      "EPOCH 430 LOSS 38658\n",
      "432 / 500\n",
      "EPOCH 431 LOSS 40798\n",
      "433 / 500\n",
      "EPOCH 432 LOSS 38874\n",
      "434 / 500\n",
      "EPOCH 433 LOSS 34585\n",
      "435 / 500\n",
      "EPOCH 434 LOSS 31942\n",
      "436 / 500\n",
      "EPOCH 435 LOSS 49114\n",
      "437 / 500\n",
      "EPOCH 436 LOSS 33955\n",
      "438 / 500\n",
      "EPOCH 437 LOSS 36857\n",
      "439 / 500\n",
      "EPOCH 438 LOSS 41263\n",
      "440 / 500\n",
      "EPOCH 439 LOSS 30251\n",
      "441 / 500\n",
      "EPOCH 440 LOSS 34590\n",
      "442 / 500\n",
      "EPOCH 441 LOSS 33095\n",
      "443 / 500\n",
      "EPOCH 442 LOSS 39549\n",
      "444 / 500\n",
      "EPOCH 443 LOSS 30344\n",
      "445 / 500\n",
      "EPOCH 444 LOSS 38080\n",
      "446 / 500\n",
      "EPOCH 445 LOSS 40993\n",
      "447 / 500\n",
      "EPOCH 446 LOSS 38761\n",
      "448 / 500\n",
      "EPOCH 447 LOSS 42933\n",
      "449 / 500\n",
      "EPOCH 448 LOSS 51229\n",
      "450 / 500\n",
      "EPOCH 449 LOSS 34502\n",
      "451 / 500\n",
      "EPOCH 450 LOSS 38615\n",
      "452 / 500\n",
      "EPOCH 451 LOSS 42724\n",
      "453 / 500\n",
      "EPOCH 452 LOSS 34957\n",
      "454 / 500\n",
      "EPOCH 453 LOSS 44450\n",
      "455 / 500\n",
      "EPOCH 454 LOSS 40106\n",
      "456 / 500\n",
      "EPOCH 455 LOSS 45799\n",
      "457 / 500\n",
      "EPOCH 456 LOSS 31585\n",
      "458 / 500\n",
      "EPOCH 457 LOSS 37701\n",
      "459 / 500\n",
      "EPOCH 458 LOSS 34036\n",
      "460 / 500\n",
      "EPOCH 459 LOSS 32419\n",
      "461 / 500\n",
      "EPOCH 460 LOSS 41346\n",
      "462 / 500\n",
      "EPOCH 461 LOSS 34285\n",
      "463 / 500\n",
      "EPOCH 462 LOSS 37073\n",
      "464 / 500\n",
      "EPOCH 463 LOSS 36740\n",
      "465 / 500\n",
      "EPOCH 464 LOSS 34381\n",
      "466 / 500\n",
      "EPOCH 465 LOSS 32077\n",
      "467 / 500\n",
      "EPOCH 466 LOSS 31441\n",
      "468 / 500\n",
      "EPOCH 467 LOSS 35349\n",
      "469 / 500\n",
      "EPOCH 468 LOSS 34118\n",
      "470 / 500\n",
      "EPOCH 469 LOSS 37189\n",
      "471 / 500\n",
      "EPOCH 470 LOSS 35018\n",
      "472 / 500\n",
      "EPOCH 471 LOSS 35023\n",
      "473 / 500\n",
      "EPOCH 472 LOSS 34291\n",
      "474 / 500\n",
      "EPOCH 473 LOSS 31367\n",
      "475 / 500\n",
      "EPOCH 474 LOSS 39483\n",
      "476 / 500\n",
      "EPOCH 475 LOSS 32815\n",
      "477 / 500\n",
      "EPOCH 476 LOSS 40588\n",
      "478 / 500\n",
      "EPOCH 477 LOSS 38566\n",
      "479 / 500\n",
      "EPOCH 478 LOSS 36587\n",
      "480 / 500\n",
      "EPOCH 479 LOSS 38543\n",
      "481 / 500\n",
      "EPOCH 480 LOSS 33136\n",
      "482 / 500\n",
      "EPOCH 481 LOSS 36502\n",
      "483 / 500\n",
      "EPOCH 482 LOSS 32687\n",
      "484 / 500\n",
      "EPOCH 483 LOSS 40519\n",
      "485 / 500\n",
      "EPOCH 484 LOSS 42597\n",
      "486 / 500\n",
      "EPOCH 485 LOSS 30947\n",
      "487 / 500\n",
      "EPOCH 486 LOSS 36201\n",
      "488 / 500\n",
      "EPOCH 487 LOSS 31718\n",
      "489 / 500\n",
      "EPOCH 488 LOSS 38935\n",
      "490 / 500\n",
      "EPOCH 489 LOSS 32432\n",
      "491 / 500\n",
      "EPOCH 490 LOSS 36996\n",
      "492 / 500\n",
      "EPOCH 491 LOSS 30997\n",
      "493 / 500\n",
      "EPOCH 492 LOSS 36286\n",
      "494 / 500\n",
      "EPOCH 493 LOSS 36849\n",
      "495 / 500\n",
      "EPOCH 494 LOSS 30348\n",
      "496 / 500\n",
      "EPOCH 495 LOSS 37307\n",
      "497 / 500\n",
      "EPOCH 496 LOSS 37830\n",
      "498 / 500\n",
      "EPOCH 497 LOSS 31165\n",
      "499 / 500\n",
      "EPOCH 498 LOSS 35586\n",
      "500 / 500\n",
      "EPOCH 499 LOSS 33028\n"
     ]
    }
   ],
   "source": [
    "cdl = CDL(rating_matrix.todense() , item_infomation_matrix)\n",
    "U, V = cdl.training() #188910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Flushing output cache (0 entries)\n"
     ]
    }
   ],
   "source": [
    "%reset Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'/home/neopux/UHH/datasets/cdl_U_mx_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(U, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(r'/home/neopux/UHH/datasets/cdl_V_mx_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(V, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'/home/neopux/UHH/datasets/cdl_U_mx_train.pickle', 'rb') as handle:\n",
    "    U = pickle.load(handle)  \n",
    "    \n",
    "with open(r'/home/neopux/UHH/datasets/cdl_V_mx_train.pickle', 'rb') as handle2:\n",
    "    V = pickle.load(handle2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 24280)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10666, 50)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = U.transpose() * V.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24280, 10666)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24280, 10666)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.matrix"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2900202161173118"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(rating_matrix.todense(), preds) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-41c19081985b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviewerID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'asin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'preds_df' is not defined"
     ]
    }
   ],
   "source": [
    "df_train_merged = df_train.merge(preds_df, on=['reviewerID', 'asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTextProc</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B008CP6MA2</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>Great game, one of the best Playstation games ...</td>\n",
       "      <td>09 5, 2013</td>\n",
       "      <td>A1GFH98ATO6D5I</td>\n",
       "      <td>Anvibe \"anvibe\"</td>\n",
       "      <td>Impressive game</td>\n",
       "      <td>1378339200</td>\n",
       "      <td>great game good playstation game the price inc...</td>\n",
       "      <td>0.002949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0050SVGW8</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>4</td>\n",
       "      <td>I compare this game to Mario Bros. Wii,and Don...</td>\n",
       "      <td>03 18, 2012</td>\n",
       "      <td>A2NBT073SQ4MXA</td>\n",
       "      <td>JASON</td>\n",
       "      <td>fun,a bit childish,and a boring soundtrack.</td>\n",
       "      <td>1332028800</td>\n",
       "      <td>i compare game mario bros. wii donkey kong cou...</td>\n",
       "      <td>0.005494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  B008CP6MA2  [0, 0]        5   \n",
       "1  B0050SVGW8  [0, 0]        4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Great game, one of the best Playstation games ...   09 5, 2013   \n",
       "1  I compare this game to Mario Bros. Wii,and Don...  03 18, 2012   \n",
       "\n",
       "       reviewerID     reviewerName  \\\n",
       "0  A1GFH98ATO6D5I  Anvibe \"anvibe\"   \n",
       "1  A2NBT073SQ4MXA            JASON   \n",
       "\n",
       "                                       summary  unixReviewTime  \\\n",
       "0                              Impressive game      1378339200   \n",
       "1  fun,a bit childish,and a boring soundtrack.      1332028800   \n",
       "\n",
       "                                      reviewTextProc     value  \n",
       "0  great game good playstation game the price inc...  0.002949  \n",
       "1  i compare game mario bros. wii donkey kong cou...  0.005494  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.128256555954819"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(df_train_merged.overall, df_train_merged.value) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((df_train_merged.overall - df_train_merged.value < 1) & (df_train_merged.overall > 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Flushing output cache (1 entries)\n"
     ]
    }
   ],
   "source": [
    "%reset Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>asin</th>\n",
       "      <th>0700099867</th>\n",
       "      <th>6050036071</th>\n",
       "      <th>7100027950</th>\n",
       "      <th>7293000936</th>\n",
       "      <th>8176503290</th>\n",
       "      <th>907843905X</th>\n",
       "      <th>9625990674</th>\n",
       "      <th>9861019731</th>\n",
       "      <th>9882155456</th>\n",
       "      <th>B000003SQQ</th>\n",
       "      <th>...</th>\n",
       "      <th>B00J128FPA</th>\n",
       "      <th>B00J226358</th>\n",
       "      <th>B00J6DLPLK</th>\n",
       "      <th>B00J9P3KBS</th>\n",
       "      <th>B00JM3R6M6</th>\n",
       "      <th>B00JQ8YH6A</th>\n",
       "      <th>B00JQHU9RC</th>\n",
       "      <th>B00JXW6GE0</th>\n",
       "      <th>B00KAI3KW2</th>\n",
       "      <th>B00KHECZXO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A00263941WP7WCIL7AKWL</th>\n",
       "      <td>0.036217</td>\n",
       "      <td>-0.042771</td>\n",
       "      <td>0.142428</td>\n",
       "      <td>0.034893</td>\n",
       "      <td>-0.035349</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>0.017174</td>\n",
       "      <td>0.067424</td>\n",
       "      <td>-0.027854</td>\n",
       "      <td>0.048216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032131</td>\n",
       "      <td>0.158985</td>\n",
       "      <td>0.042688</td>\n",
       "      <td>-0.108086</td>\n",
       "      <td>0.086972</td>\n",
       "      <td>-0.053289</td>\n",
       "      <td>-0.046670</td>\n",
       "      <td>-0.090321</td>\n",
       "      <td>0.033316</td>\n",
       "      <td>-0.066040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A005481137I9SCAWEF7ON</th>\n",
       "      <td>0.231518</td>\n",
       "      <td>0.211260</td>\n",
       "      <td>0.122527</td>\n",
       "      <td>0.219639</td>\n",
       "      <td>0.094767</td>\n",
       "      <td>0.090912</td>\n",
       "      <td>0.137666</td>\n",
       "      <td>0.135985</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.063811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206081</td>\n",
       "      <td>0.309379</td>\n",
       "      <td>0.208197</td>\n",
       "      <td>-0.033302</td>\n",
       "      <td>0.167693</td>\n",
       "      <td>0.113970</td>\n",
       "      <td>0.121568</td>\n",
       "      <td>0.041478</td>\n",
       "      <td>-0.107656</td>\n",
       "      <td>0.082672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 10666 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "asin                   0700099867  6050036071  7100027950  7293000936  \\\n",
       "reviewerID                                                              \n",
       "A00263941WP7WCIL7AKWL    0.036217   -0.042771    0.142428    0.034893   \n",
       "A005481137I9SCAWEF7ON    0.231518    0.211260    0.122527    0.219639   \n",
       "\n",
       "asin                   8176503290  907843905X  9625990674  9861019731  \\\n",
       "reviewerID                                                              \n",
       "A00263941WP7WCIL7AKWL   -0.035349    0.060498    0.017174    0.067424   \n",
       "A005481137I9SCAWEF7ON    0.094767    0.090912    0.137666    0.135985   \n",
       "\n",
       "asin                   9882155456  B000003SQQ  ...  B00J128FPA  B00J226358  \\\n",
       "reviewerID                                     ...                           \n",
       "A00263941WP7WCIL7AKWL   -0.027854    0.048216  ...    0.032131    0.158985   \n",
       "A005481137I9SCAWEF7ON    0.019068    0.063811  ...    0.206081    0.309379   \n",
       "\n",
       "asin                   B00J6DLPLK  B00J9P3KBS  B00JM3R6M6  B00JQ8YH6A  \\\n",
       "reviewerID                                                              \n",
       "A00263941WP7WCIL7AKWL    0.042688   -0.108086    0.086972   -0.053289   \n",
       "A005481137I9SCAWEF7ON    0.208197   -0.033302    0.167693    0.113970   \n",
       "\n",
       "asin                   B00JQHU9RC  B00JXW6GE0  B00KAI3KW2  B00KHECZXO  \n",
       "reviewerID                                                             \n",
       "A00263941WP7WCIL7AKWL   -0.046670   -0.090321    0.033316   -0.066040  \n",
       "A005481137I9SCAWEF7ON    0.121568    0.041478   -0.107656    0.082672  \n",
       "\n",
       "[2 rows x 10666 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df_unmelt = pd.DataFrame(preds, columns = col_cat.categories, index = row_cat.categories)\n",
    "preds_df_unmelt.index.name = 'reviewerID'\n",
    "preds_df_unmelt.columns.name = 'asin'\n",
    "preds_df_unmelt.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00263941WP7WCIL7AKWL</td>\n",
       "      <td>0700099867</td>\n",
       "      <td>0.036217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A005481137I9SCAWEF7ON</td>\n",
       "      <td>0700099867</td>\n",
       "      <td>0.231518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewerID        asin     value\n",
       "0  A00263941WP7WCIL7AKWL  0700099867  0.036217\n",
       "1  A005481137I9SCAWEF7ON  0700099867  0.231518"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = preds_df_unmelt.reset_index().melt('reviewerID', var_name='asin')\n",
    "preds_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTextProc</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0000C6EB4</td>\n",
       "      <td>[7, 7]</td>\n",
       "      <td>5</td>\n",
       "      <td>If you're looking for a far more rewarding and...</td>\n",
       "      <td>11 6, 2003</td>\n",
       "      <td>AWXPAJ7VG5D4Y</td>\n",
       "      <td>Philip Lochner</td>\n",
       "      <td>The Definitive WW2 FPS</td>\n",
       "      <td>1068076800</td>\n",
       "      <td>if be look far rewarding enjoyable experience ...</td>\n",
       "      <td>-0.039016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000B6ML1Y</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>The game is awesome...using gadgets playing co...</td>\n",
       "      <td>07 3, 2007</td>\n",
       "      <td>A3L2ORVGVM3UET</td>\n",
       "      <td>A. Gift For You \"I am THE godman\"</td>\n",
       "      <td>Love it</td>\n",
       "      <td>1183420800</td>\n",
       "      <td>the game awesome gadget play co op online frie...</td>\n",
       "      <td>0.003322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  B0000C6EB4  [7, 7]        5   \n",
       "1  B000B6ML1Y  [0, 2]        5   \n",
       "\n",
       "                                          reviewText  reviewTime  \\\n",
       "0  If you're looking for a far more rewarding and...  11 6, 2003   \n",
       "1  The game is awesome...using gadgets playing co...  07 3, 2007   \n",
       "\n",
       "       reviewerID                       reviewerName                 summary  \\\n",
       "0   AWXPAJ7VG5D4Y                     Philip Lochner  The Definitive WW2 FPS   \n",
       "1  A3L2ORVGVM3UET  A. Gift For You \"I am THE godman\"                 Love it   \n",
       "\n",
       "   unixReviewTime                                     reviewTextProc     value  \n",
       "0      1068076800  if be look far rewarding enjoyable experience ... -0.039016  \n",
       "1      1183420800  the game awesome gadget play co op online frie...  0.003322  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = df_test.merge(preds_df, on=['reviewerID', 'asin'])\n",
    "df_merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69534, 10)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69378, 11)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.186046002615581"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(df_merged.overall, df_merged.value) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16418"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((df_merged.overall - df_merged.value) < 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ((df_merged.overall - df_merged.value < 1) & (df_merged.overall > 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 11)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[idx].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
