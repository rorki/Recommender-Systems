{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conventional Matrix Factorization & Random Predictor Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all aux imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import csv\n",
    "import pyximport\n",
    "pyximport.install()\n",
    "\n",
    "from utils_metrics import precision_recall_at_k_4ds\n",
    "from utils_xp_out import write_to_csv, XPDescription, XPResults\n",
    "\n",
    "# random seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# surplrise lib\n",
    "from surprise import Dataset, Reader, SVD, NormalPredictor\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# visualizaion\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "XP_NAME = 'baselines'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and run predictors per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [XPDescription(predictor = NormalPredictor(), label = 'Normal Predictor', nfactors = None),\n",
    "              XPDescription(predictor = SVD(n_factors = 15, lr_all=0.002, n_epochs=120, reg_all=0.05), label = 'SVD-15', nfactors = 15),\n",
    "              XPDescription(predictor = SVD(n_factors = 30, lr_all=0.002, n_epochs=120, reg_all=0.05), label = 'SVD-30', nfactors = 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_complete_ds(file):\n",
    "    chunk_num = 1 \n",
    "    \n",
    "    dfs = []\n",
    "    print('Chunks: ', end='')\n",
    "    for df_chunky in pd.read_json(str(file), lines=True, compression = 'gzip', chunksize=1000000):\n",
    "        print('#%s' % chunk_num, end=' ')\n",
    "        chunk_num += 1\n",
    "        dfs.append(df_chunky[['reviewerID', 'asin', 'overall']].copy())\n",
    "        \n",
    "    complete_df = pd.concat(dfs)\n",
    "    print(\"\\nLoading is completed, df shape %s x %s\" % complete_df.shape)\n",
    "    return complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions):\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "    mae = accuracy.mae(predictions, verbose=False)\n",
    "\n",
    "    k_prec = {}\n",
    "    k_rec = {}\n",
    "\n",
    "    for k in range(0, 200):\n",
    "        precisions, recalls = precision_recall_at_k_4ds(predictions, k=k, threshold=3) \n",
    "        p_mean = np.mean(list(precisions.values()))\n",
    "        r_mean = np.mean(list(recalls.values()))\n",
    "        k_prec[k] = p_mean\n",
    "        k_rec[k] = r_mean\n",
    "        \n",
    "    return rmse, mae, k_prec, k_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for: Video Games\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 231780 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "Run predictor SVD-15\n",
      "Write eval data to file\n",
      "Run predictor SVD-30\n",
      "Write eval data to file\n",
      "Loading data for: Toys and Games\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 167597 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "Run predictor SVD-15\n",
      "Write eval data to file\n",
      "Run predictor SVD-30\n",
      "Write eval data to file\n",
      "Loading data for: Sports and Outdoors\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 296337 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "Run predictor SVD-15\n",
      "Write eval data to file\n",
      "Run predictor SVD-30\n",
      "Write eval data to file\n",
      "Loading data for: Movies and TV\n",
      "Chunks: #1 #2 \n",
      "Loading is completed, df shape 1697533 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "Run predictor SVD-15\n",
      "Write eval data to file\n",
      "Run predictor SVD-30\n",
      "Write eval data to file\n",
      "Loading data for: Kindle Store\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 982619 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "Run predictor SVD-15\n",
      "Write eval data to file\n",
      "Run predictor SVD-30\n",
      "Write eval data to file\n",
      "Loading data for: Home and Kitchen\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 551682 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "Run predictor SVD-15\n",
      "Write eval data to file\n",
      "Run predictor SVD-30\n",
      "Write eval data to file\n",
      "Loading data for: Health and Personal Care\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 346355 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "Run predictor SVD-15\n",
      "Write eval data to file\n",
      "Run predictor SVD-30\n",
      "Write eval data to file\n",
      "Loading data for: Electronics\n",
      "Chunks: #1 #2 \n",
      "Loading is completed, df shape 1689188 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "Run predictor SVD-15\n",
      "Write eval data to file\n",
      "Run predictor SVD-30\n",
      "Write eval data to file\n",
      "Loading data for: Clothing Shoes and Jewelry\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 278677 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "Run predictor SVD-15\n",
      "Write eval data to file\n",
      "Run predictor SVD-30\n",
      "Write eval data to file\n",
      "Loading data for: Cell Phones and Accessories\n",
      "Chunks: #1 \n",
      "Loading is completed, df shape 194439 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "Run predictor SVD-15\n",
      "Write eval data to file\n",
      "Run predictor SVD-30\n",
      "Write eval data to file\n",
      "Loading data for: CDs and Vinyl\n",
      "Chunks: #1 #2 \n",
      "Loading is completed, df shape 1097592 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "Run predictor SVD-15\n",
      "Write eval data to file\n",
      "Run predictor SVD-30\n",
      "Write eval data to file\n",
      "Loading data for: Books\n",
      "Chunks: #1 #2 #3 #4 #5 #6 #7 #8 #9 \n",
      "Loading is completed, df shape 8898041 x 3\n",
      "Run predictor Normal Predictor\n",
      "Write eval data to file\n",
      "Run predictor SVD-15\n",
      "Write eval data to file\n",
      "Run predictor SVD-30\n",
      "Write eval data to file\n"
     ]
    }
   ],
   "source": [
    "parent_path = r'D:\\Datasets\\amazon_reviews\\gzips'\n",
    "files = [Path(f) for f in glob.glob(parent_path  + r\"\\*.gz\", recursive=False)]\n",
    "files.reverse()\n",
    "\n",
    "for file in files:\n",
    "    label = ' '.join(file.stem.split('_')[1:-1])\n",
    "    print('Loading data for: ' + label)              \n",
    "    \n",
    "    complete_df = read_complete_ds(file)\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    ds = Dataset.load_from_df(complete_df[['reviewerID', 'asin', 'overall']], reader)\n",
    "    trainset, testset = train_test_split(ds, random_state=42, test_size=0.3)\n",
    "    \n",
    "    for pred in predictors:\n",
    "        print(\"Run predictor %s\" % pred.label)\n",
    "        \n",
    "        pred.predictor.fit(trainset)\n",
    "        predictions = pred.predictor.test(testset)\n",
    "        \n",
    "        print(\"Write eval data to file\")\n",
    "        rmse, mae, k_prec, k_rec = evaluate(predictions)\n",
    "        row = XPResults(dataset=label, xpdata=pred, rmse=rmse, mae=mae, precision=k_prec, recall=k_rec)\n",
    "        write_to_csv(row, XP_NAME)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks: #1 \n",
      "Loading is completed, df shape 194439 x 3\n"
     ]
    }
   ],
   "source": [
    "complete_df = read_complete_ds(Path(r'D:\\Datasets\\amazon_reviews\\gzips\\reviews_Cell_Phones_and_Accessories_5.json.gz'))\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "ds = Dataset.load_from_df(complete_df[['reviewerID', 'asin', 'overall']], reader)\n",
    "trainset, testset = train_test_split(ds, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratings = ds.raw_ratings\n",
    "random.shuffle(raw_ratings)\n",
    "\n",
    "threshold = int(.7 * len(raw_ratings))\n",
    "train_raw_ratings = raw_ratings[:threshold]\n",
    "test_raw_ratings = raw_ratings[threshold:]\n",
    "\n",
    "ds.raw_ratings = train_raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=10)]: Done 324 out of 324 | elapsed: 13.8min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_epochs': [50, 100, 150], 'lr_all': [0.001, 0.002, 0.003], \n",
    "              'n_factors':[10, 12, 15, 17], 'reg_all': [0.05, 0.06, 0.07]}\n",
    "\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=10, joblib_verbose=1)\n",
    "grid_search.fit(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr_all': 0.002, 'n_epochs': 50, 'n_factors': 12, 'reg_all': 0.05}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr_all': 0.002, 'n_epochs': 150, 'n_factors': 10, 'reg_all': 0.07}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params['mae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1483129315790315, MAE: 0.8890311814329908\n"
     ]
    }
   ],
   "source": [
    "trainset = ds.build_full_trainset()\n",
    "algo = grid_search.best_estimator['rmse']\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(ds.construct_testset(test_raw_ratings))\n",
    "rmse, mae, k_prec, k_rec = evaluate(predictions)\n",
    "print('RMSE: %s, MAE: %s' % (rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.164126078187515, MAE: 0.8760092479109463\n"
     ]
    }
   ],
   "source": [
    "algo = grid_search.best_estimator['mae']\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(ds.construct_testset(test_raw_ratings))\n",
    "rmse, mae, k_prec, k_rec = evaluate(predictions)\n",
    "print('RMSE: %s, MAE: %s' % (rmse, mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cat | mae best | mae | rmse | rmse best | mae | rmse\n",
    "--- | --- | --- | --- | --- | --- | --- |\n",
    "Movies and TV | {'lr_all': 0.002, 'n_epochs': 100, 'n_factors': 15, 'reg_all': 0.05} | 0.746238556042999 | 1.0126716530928812 | {'lr_all': 0.003, 'n_epochs': 50, 'n_factors': 15, 'reg_all': 0.05} | 0.7485903901212774 | 1.0077799950679822 | \n",
    "Video_Games | {'lr_all': 0.003, 'n_epochs': 100, 'n_factors': 15, 'reg_all': 0.04} | 0.8128197857525622 | 1.0819106948711148 | {'lr_all': 0.001, 'n_epochs': 150, 'n_factors': 20, 'reg_all': 0.04} | 0.8211216841776046 | 1.074492851316181  |\n",
    "Cell Phones and Accessories | {'lr_all': 0.002, 'n_epochs': 150, 'n_factors': 10, 'reg_all': 0.07} | 0.8760092479109463 | 1.164126078187515 | {'lr_all': 0.002, 'n_epochs': 50, 'n_factors': 12, 'reg_all': 0.05} | 0.8890311814329908 | 1.1483129315790315|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
