{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "#init random seed\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build item information matrix of citeulike-a by bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('D:/Datasets/amazon_reviews/Video_Games_5_proc.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTextProc</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>[8, 12]</td>\n",
       "      <td>1</td>\n",
       "      <td>Installing the game was a struggle (because of...</td>\n",
       "      <td>instal game struggle game window live bugs).so...</td>\n",
       "      <td>07 9, 2012</td>\n",
       "      <td>A2HD75EMZR8QLN</td>\n",
       "      <td>123</td>\n",
       "      <td>Pay to unlock content? I don't think so.</td>\n",
       "      <td>1341792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>4</td>\n",
       "      <td>If you like rally cars get this game you will ...</td>\n",
       "      <td>if like rally car game fun it orient 34;europe...</td>\n",
       "      <td>06 30, 2013</td>\n",
       "      <td>A3UR8NLLY1ZHCX</td>\n",
       "      <td>Alejandro Henao \"Electronic Junky\"</td>\n",
       "      <td>Good rally game</td>\n",
       "      <td>1372550400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0700099867</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>I'm not quite finished with the game's DiRT To...</td>\n",
       "      <td>i be finish game 's dirt tour mode i believe i...</td>\n",
       "      <td>06 28, 2011</td>\n",
       "      <td>A38NXTZUFB1O2K</td>\n",
       "      <td>FiSH</td>\n",
       "      <td>Best in the series!</td>\n",
       "      <td>1309219200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>9882155456</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>They work fine but i feel like they have a lit...</td>\n",
       "      <td>they work fine feel like little lag control us...</td>\n",
       "      <td>01 7, 2014</td>\n",
       "      <td>A19IX3U60WJL1V</td>\n",
       "      <td>Edgar</td>\n",
       "      <td>works but flawed.</td>\n",
       "      <td>1389052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>B00000I1BE</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>5</td>\n",
       "      <td>This game in my opinion is the best of all the...</td>\n",
       "      <td>this game opinion good castlevania series far ...</td>\n",
       "      <td>10 3, 2000</td>\n",
       "      <td>A2U7ABLSDAITGC</td>\n",
       "      <td>D. Lewis</td>\n",
       "      <td>Castlevania Mania</td>\n",
       "      <td>970531200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            asin  helpful  overall  \\\n",
       "0     0700099867  [8, 12]        1   \n",
       "1     0700099867   [0, 0]        4   \n",
       "10    0700099867   [1, 1]        5   \n",
       "100   9882155456   [0, 0]        3   \n",
       "1000  B00000I1BE  [8, 10]        5   \n",
       "\n",
       "                                             reviewText  \\\n",
       "0     Installing the game was a struggle (because of...   \n",
       "1     If you like rally cars get this game you will ...   \n",
       "10    I'm not quite finished with the game's DiRT To...   \n",
       "100   They work fine but i feel like they have a lit...   \n",
       "1000  This game in my opinion is the best of all the...   \n",
       "\n",
       "                                         reviewTextProc   reviewTime  \\\n",
       "0     instal game struggle game window live bugs).so...   07 9, 2012   \n",
       "1     if like rally car game fun it orient 34;europe...  06 30, 2013   \n",
       "10    i be finish game 's dirt tour mode i believe i...  06 28, 2011   \n",
       "100   they work fine feel like little lag control us...   01 7, 2014   \n",
       "1000  this game opinion good castlevania series far ...   10 3, 2000   \n",
       "\n",
       "          reviewerID                        reviewerName  \\\n",
       "0     A2HD75EMZR8QLN                                 123   \n",
       "1     A3UR8NLLY1ZHCX  Alejandro Henao \"Electronic Junky\"   \n",
       "10    A38NXTZUFB1O2K                                FiSH   \n",
       "100   A19IX3U60WJL1V                               Edgar   \n",
       "1000  A2U7ABLSDAITGC                            D. Lewis   \n",
       "\n",
       "                                       summary  unixReviewTime  \n",
       "0     Pay to unlock content? I don't think so.      1341792000  \n",
       "1                              Good rally game      1372550400  \n",
       "10                         Best in the series!      1309219200  \n",
       "100                          works but flawed.      1389052800  \n",
       "1000                         Castlevania Mania       970531200  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df.groupby('asin').reviewTextProc.agg(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "vectorizer.fit(reviews.values)\n",
    "\n",
    "X_train = vectorizer.transform(reviews.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10672, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vamp', 9456),\n",
       " ('xbox360', 9915),\n",
       " ('overworld', 6299),\n",
       " ('corpse', 2045),\n",
       " ('lighthearted', 5125),\n",
       " ('tout', 9049),\n",
       " ('pearl', 6427),\n",
       " ('fix', 3440),\n",
       " ('lacking', 4983),\n",
       " ('sc2', 7662)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectorizer.vocabulary_.items())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elisa',\n",
       " 'cmcr1',\n",
       " 'playingbattlefield',\n",
       " 'punkboney',\n",
       " 'undeground',\n",
       " 'trophies3d',\n",
       " 'ps3250',\n",
       " 'actionsequence',\n",
       " 'handmade',\n",
       " 'tradeskill']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectorizer.stop_words_)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find vocabulary_size = 8000\n",
    "with open(r\"ctrsr_datasets/citeulike-a/vocabulary.dat\") as vocabulary_file:\n",
    "    vocabulary_size = len(vocabulary_file.readlines())\n",
    "    \n",
    "#find item_size = 16980\n",
    "with open(r\"ctrsr_datasets/citeulike-a/mult.dat\") as item_info_file:\n",
    "    item_size = len(item_info_file.readlines())\n",
    "\n",
    "#initialize item_infomation_matrix (16980 , 8000)\n",
    "item_infomation_matrix = np.zeros((item_size , vocabulary_size))\n",
    "\n",
    "#build item_infomation_matrix\n",
    "with open(r\"ctrsr_datasets/citeulike-a/mult.dat\") as item_info_file:\n",
    "    sentences = item_info_file.readlines()\n",
    "    \n",
    "    for index,sentence in enumerate(sentences):\n",
    "        words = sentence.strip().split(\" \")[1:]\n",
    "        for word in words:\n",
    "            vocabulary_index , number = word.split(\":\")\n",
    "            item_infomation_matrix[index][int(vocabulary_index)] =number\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build rating matrix citeulike-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find user_size = 5551\n",
    "with open(r\"ctrsr_datasets/citeulike-a/users.dat\") as rating_file:\n",
    "    user_size = len(rating_file.readlines())\n",
    "\n",
    "#initialize rating_matrix (5551 , 16980)\n",
    "import numpy as np\n",
    "rating_matrix = np.zeros((user_size , item_size))\n",
    "\n",
    "#build rating_matrix\n",
    "with open(r\"ctrsr_datasets/citeulike-a/users.dat\") as rating_file:\n",
    "    lines = rating_file.readlines()\n",
    "    for index,line in enumerate(lines):\n",
    "        items = line.strip().split(\" \")\n",
    "        for item in items:  \n",
    "            rating_matrix[index][int(item)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save matrix by pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'item_infomation_matrix.pickle', 'wb') as handle:\n",
    "    pickle.dump(item_infomation_matrix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(r'rating_matrix.pickle', 'wb') as handle:\n",
    "    pickle.dump(rating_matrix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load matrix from pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'item_infomation_matrix.pickle', 'rb') as handle:\n",
    "    item_infomation_matrix = pickle.load(handle)  \n",
    "    \n",
    "with open(r'rating_matrix.pickle', 'rb') as handle2:\n",
    "    rating_matrix = pickle.load(handle2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix factorization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF():\n",
    "    def __init__(self , rating_matrix ):\n",
    "        #### 參數設定\n",
    "        self.num_u = rating_matrix.shape[0] #5551\n",
    "        self.num_v = rating_matrix.shape[1] #16980\n",
    "        self.u_lambda = 100\n",
    "        self.v_lambda = 0.1\n",
    "        self.k = 50 #latent維度\n",
    "        self.a = 1\n",
    "        self.b =0.01\n",
    "        self.R = np.mat(rating_matrix)\n",
    "        self.C = np.mat(np.ones(self.R.shape)) * self.b\n",
    "        self.C[np.where(self.R>0)] = self.a\n",
    "        self.I_U = np.mat(np.eye(self.k) * self.u_lambda)\n",
    "        self.I_V = np.mat(np.eye(self.k) * self.v_lambda)\n",
    "        self.U = np.mat(np.random.normal(0 , 1/self.u_lambda , size=(self.k,self.num_u)))\n",
    "        self.V = np.mat(np.random.normal(0 , 1/self.v_lambda , size=(self.k,self.num_v)))\n",
    "                        \n",
    "\n",
    "    def test(self):\n",
    "        print( ((U_cut*self.R[np.ravel(np.where(self.R[:,j]>0)[1]),j] + self.v_lambda * self.V_sdae[j])).shape)\n",
    "    def ALS(self , V_sdae):\n",
    "        self.V_sdae = np.mat(V_sdae)\n",
    "        \n",
    "        V_sq = self.V * self.V.T * self.b\n",
    "        for i in range(self.num_u):\n",
    "            idx_a = np.ravel(np.where(self.R[i,:]>0)[1])\n",
    "            V_cut = self.V[:,idx_a]\n",
    "            self.U[:,i] = np.linalg.pinv( V_sq+ V_cut * V_cut.T * (self.a-self.b) + self.I_U )*(V_cut*self.R[i,idx_a].T) #V_sq+V_cut*V_cut.T*a_m_b = VCV^T\n",
    "        \n",
    "        U_sq = self.U * self.U.T * self.b\n",
    "        for j in range(self.num_v):\n",
    "            idx_a = np.ravel(np.where(self.R[:,j]>0)[1])\n",
    "            U_cut = self.U[:,idx_a]\n",
    "            self.V[:,j] = np.linalg.pinv(U_sq+U_cut*U_cut.T*(self.a-self.b)+self.I_V)* (U_cut*self.R[idx_a,j] + self.v_lambda * np.resize(self.V_sdae[j],(self.k,1)))\n",
    "        \n",
    "        return self.U ,self.V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### masking noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(corruption_level ,size):\n",
    "    mask = np.random.binomial(1, 1 - corruption_level, [size[0],size[1]])\n",
    "    return mask\n",
    "\n",
    "def add_noise(x , corruption_level ):\n",
    "    x = x * mask(corruption_level , x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDL():\n",
    "    def __init__(self , rating_matrix , item_infomation_matrix):\n",
    "        # model參數設定\n",
    "        self.n_input = 8000\n",
    "        self.n_hidden1 = 200\n",
    "        self.n_hidden2 = 50\n",
    "        self.k = 50\n",
    "        \n",
    "        self.lambda_w = 1\n",
    "        self.lambda_n = 1\n",
    "        self.lambda_u = 1\n",
    "        self.lambda_v = 1\n",
    "        \n",
    "        self.drop_ratio = 0.1\n",
    "        self.learning_rate = 0.001\n",
    "        self.epochs = 10\n",
    "        self.batch_size = 32\n",
    "        \n",
    "        self.num_u = rating_matrix.shape[0]\n",
    "        self.num_v = rating_matrix.shape[1]\n",
    "        \n",
    "        self.Weights = {\n",
    "            'w1' : tf.Variable(tf.random_normal( [self.n_input , self.n_hidden1] , mean=0.0, stddev=1 / self.lambda_w )),\n",
    "            'w2' : tf.Variable(tf.random_normal( [self.n_hidden1 , self.n_hidden2] , mean=0.0, stddev=1 / self.lambda_w )),\n",
    "            'w3' : tf.Variable(tf.random_normal( [self.n_hidden2 , self.n_hidden1] , mean=0.0, stddev=1 / self.lambda_w )),\n",
    "            'w4' : tf.Variable(tf.random_normal( [self.n_hidden1 , self.n_input] , mean=0.0, stddev=1 / self.lambda_w ))   \n",
    "        }\n",
    "        self.Biases = {\n",
    "            'b1' : tf.Variable(tf.random_normal( [self.n_hidden1] , mean=0.0, stddev=1 / self.lambda_w )),\n",
    "            'b2' : tf.Variable(tf.random_normal( [self.n_hidden2] , mean=0.0, stddev=1 / self.lambda_w )),\n",
    "            'b3' : tf.Variable(tf.random_normal( [self.n_hidden1] , mean=0.0, stddev=1 / self.lambda_w )),\n",
    "            'b4' : tf.Variable(tf.random_normal( [self.n_input] , mean=0.0, stddev=1 / self.lambda_w ))\n",
    "        }\n",
    "        \n",
    "        self.item_infomation_matrix = item_infomation_matrix\n",
    "    \n",
    "        self.build_model()\n",
    "    def encoder(self , x , drop_ratio):\n",
    "        w1 = self.Weights['w1']\n",
    "        b1 = self.Biases['b1']\n",
    "        L1 = tf.nn.sigmoid( tf.matmul(x,w1) + b1 )\n",
    "        L1 = tf.nn.dropout( L1 , keep_prob= 1 - drop_ratio )\n",
    "        \n",
    "        w2 = self.Weights['w2']\n",
    "        b2 = self.Biases['b2']\n",
    "        L2 = tf.nn.sigmoid( tf.matmul(L1,w2) + b2 )\n",
    "        L2 = tf.nn.dropout(L2 , keep_prob= 1 - drop_ratio)\n",
    "        \n",
    "        return L2\n",
    "    \n",
    "    def decoder(self , x , drop_ratio):\n",
    "        w3 = self.Weights['w3']\n",
    "        b3 = self.Biases['b3']\n",
    "        L3 = tf.nn.sigmoid(tf.matmul(x,w3) + b3)\n",
    "        L3 = tf.nn.dropout(L3 , keep_prob= 1 - drop_ratio)\n",
    "\n",
    "        w4 = self.Weights['w4']\n",
    "        b4 = self.Biases['b4']\n",
    "        L4 = tf.nn.sigmoid(tf.matmul(L3,w4) + b4)\n",
    "        L4 = tf.nn.dropout(L4 , keep_prob= 1 - drop_ratio)\n",
    "\n",
    "        return L4\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.model_X_0 = tf.placeholder(tf.float32 , shape=(None , self.n_input))\n",
    "        self.model_X_c = tf.placeholder(tf.float32 , shape=(None , self.n_input))\n",
    "        self.model_V = tf.placeholder(tf.float32 , shape=(None , self.k))\n",
    "        self.model_drop_ratio = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self.V_sdae = self.encoder( self.model_X_0 , self.model_drop_ratio )\n",
    "        self.y_pred = self.decoder( self.V_sdae , self.model_drop_ratio )\n",
    "        \n",
    "        self.Regularization = tf.reduce_sum([tf.nn.l2_loss(w)+tf.nn.l2_loss(b) for w,b in zip(self.Weights.values() , self.Biases.values())])\n",
    "        loss_r =1/2 * self.lambda_w * self.Regularization\n",
    "        loss_a =1/2 * self.lambda_n * tf.reduce_sum(tf.pow( self.model_X_c - self.y_pred , 2 ))\n",
    "        loss_v =1/2 * self.lambda_v * tf.reduce_sum(tf.pow( self.model_V - self.V_sdae , 2 ))\n",
    "        self.Loss = loss_r + loss_a + loss_v\n",
    "        \n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.Loss)\n",
    "    \n",
    "    def training(self , rating_matrix):\n",
    "        #np.random.shuffle(self.item_infomation_matrix) #random index of train data\n",
    "        \n",
    "        self.item_infomation_matrix_noise = add_noise(self.item_infomation_matrix , 0.3)\n",
    "        \n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        mf = MF( rating_matrix )\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"%d / %d\"%(epoch+1 , self.epochs))\n",
    "            \n",
    "            V_sdae = sess.run(self.V_sdae , feed_dict={self.model_X_0 : self.item_infomation_matrix_noise , self.model_drop_ratio : 0.1})\n",
    "            \n",
    "            U , V = mf.ALS(V_sdae)\n",
    "            V = np.resize(V,(16980 , 50))\n",
    "            for i in range(0 , self.item_infomation_matrix.shape[0] , self.batch_size):\n",
    "                X_train_batch = self.item_infomation_matrix_noise[i:i+self.batch_size]\n",
    "                y_train_batch = self.item_infomation_matrix[i:i+self.batch_size]\n",
    "                V_batch = V[i:i+self.batch_size]\n",
    "                _ , my_loss = sess.run([self.optimizer, self.Loss] , feed_dict={self.model_X_0 :X_train_batch , self.model_X_c : y_train_batch , self.model_V:V_batch, self.model_drop_ratio : 0.1})\n",
    "            print(my_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10\n",
      "387677.62\n",
      "2 / 10\n",
      "175559.14\n",
      "3 / 10\n",
      "76667.734\n",
      "4 / 10\n",
      "33305.188\n",
      "5 / 10\n",
      "14436.599\n",
      "6 / 10\n",
      "6843.848\n",
      "7 / 10\n",
      "3749.5586\n",
      "8 / 10\n",
      "2751.414\n",
      "9 / 10\n",
      "2292.7659\n",
      "10 / 10\n",
      "2268.0378\n"
     ]
    }
   ],
   "source": [
    "cdl = CDL(rating_matrix , item_infomation_matrix)\n",
    "cdl.build_model()\n",
    "cdl.training(rating_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
